{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2144b5ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem .",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem ."
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem .",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem ."
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core._multiarray_umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core._multiarray_umath failed to import"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem .",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem ."
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem .",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem ."
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem .",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem ."
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem .",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem ."
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem .",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem ."
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem .",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem ."
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem .",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem ."
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem .",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem ."
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem .",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem ."
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem .",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem ."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using 32 worker processes.\n",
      "Processed 251 out of 251 files successfully.\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from joblib import Parallel, delayed  # Better parallelism\n",
    "\n",
    "# Path to the directory containing PDB files\n",
    "pdb_dir = r\"D:\\P2Rank_GNN_Dataset\\chen11\"\n",
    "\n",
    "# Get a list of all PDB files in the directory\n",
    "pdb_files = glob.glob(os.path.join(pdb_dir, \"*.pdb\"))\n",
    "\n",
    "def validate_and_fix_mol(mol):\n",
    "    \"\"\"\n",
    "    Removes atoms with invalid valences from the molecule.\n",
    "\n",
    "    Args:\n",
    "        mol (rdkit.Chem.Mol): The input molecule.\n",
    "\n",
    "    Returns:\n",
    "        rdkit.Chem.Mol: A molecule with problematic atoms removed.\n",
    "    \"\"\"\n",
    "    to_remove = [atom.GetIdx() for atom in mol.GetAtoms()\n",
    "                 if atom.GetExplicitValence() > Chem.GetPeriodicTable().GetDefaultValence(atom.GetAtomicNum())]\n",
    "\n",
    "    if to_remove:\n",
    "        editable_mol = Chem.EditableMol(mol)\n",
    "        for idx in sorted(to_remove, reverse=True):\n",
    "            editable_mol.RemoveAtom(idx)\n",
    "        return editable_mol.GetMol()\n",
    "    return mol\n",
    "\n",
    "def extract_sas_points(pdb_file):\n",
    "    \"\"\"\n",
    "    Extracts 3D coordinates for SAS points from a PDB file.\n",
    "\n",
    "    Args:\n",
    "        pdb_file (str): Path to the PDB file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (pdb_file, torch.Tensor) or None if failed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mol = Chem.MolFromPDBFile(pdb_file, removeHs=False, sanitize=False)\n",
    "        if mol is None:\n",
    "            raise RuntimeError(f\"Failed to load PDB file: {pdb_file}\")\n",
    "\n",
    "        # Validate and fix problematic atoms\n",
    "        mol = validate_and_fix_mol(mol)\n",
    "\n",
    "        # Attempt sanitization)\n",
    "        try:\n",
    "            Chem.SanitizeMol(mol)\n",
    "        except Exception as e:\n",
    "            print(f\"Sanitization failed for {pdb_file}: {e}\")\n",
    "            return None\n",
    "\n",
    "        # Extract 3D coordinates directly (skip 2D computation)\n",
    "        conf = mol.GetConformer()\n",
    "        sas_points = [[pos.x, pos.y, pos.z] for pos in (conf.GetAtomPosition(atom.GetIdx()) for atom in mol.GetAtoms())]\n",
    "\n",
    "        return pdb_file, torch.tensor(sas_points, dtype=torch.float)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdb_file}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_pdb_files_parallel(pdb_files, num_workers=None):\n",
    "    \"\"\"\n",
    "    Processes PDB files in parallel using joblib for better parallelism.\n",
    "\n",
    "    Args:\n",
    "        pdb_files (list): List of PDB file paths.\n",
    "        num_workers (int, optional): Number of processes to use. Defaults to max available.\n",
    "\n",
    "    Returns:\n",
    "        list: List of tensors containing node features.\n",
    "    \"\"\"\n",
    "    if num_workers is None:\n",
    "        num_workers = min(32, cpu_count() - 2)  # Use a maximum of 32 workers to avoid Windows limitations\n",
    "\n",
    "    print(f\"Using {num_workers} worker processes.\")\n",
    "\n",
    "    # Use joblib for parallel processing\n",
    "    results = Parallel(n_jobs=num_workers)(delayed(extract_sas_points)(file) for file in pdb_files)\n",
    "\n",
    "    # Remove failed cases\n",
    "    all_node_features = [res[1] for res in results if res is not None]\n",
    "\n",
    "    return all_node_features\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Run parallel processing\n",
    "all_node_features = process_pdb_files_parallel(pdb_files)\n",
    "\n",
    "# Move tensors to GPU if available\n",
    "all_node_features = [tensor.to(device) for tensor in all_node_features]\n",
    "\n",
    "# Print summary\n",
    "print(f\"Processed {len(all_node_features)} out of {len(pdb_files)} files successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee7a7414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed edges for 251 graphs.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def construct_edges(sas_points, distance_threshold=6.0):\n",
    "    \"\"\"\n",
    "    Constructs edges based on spatial proximity between SAS points.\n",
    "\n",
    "    Args:\n",
    "        sas_points (np.ndarray): Array of 3D coordinates of SAS points.\n",
    "        distance_threshold (float): Maximum distance to consider an edge.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array of edge pairs.\n",
    "    \"\"\"\n",
    "    if len(sas_points) == 0:\n",
    "        return np.array([])\n",
    "    \n",
    "    # Compute pairwise distance matrix\n",
    "    dist_matrix = cdist(sas_points, sas_points)\n",
    "    \n",
    "    # Identify edges where the distance is below the threshold\n",
    "    edge_indices = np.where(dist_matrix < distance_threshold)\n",
    "    \n",
    "    # Filter out duplicate edges (i < j)\n",
    "    edges = np.array([[i, j] for i, j in zip(*edge_indices) if i < j])\n",
    "    \n",
    "    return edges\n",
    "\n",
    "# Example usage\n",
    "# Assuming `all_node_features` is available from Code 1\n",
    "all_edges = []\n",
    "\n",
    "for sas_points in all_node_features:\n",
    "    sas_np = sas_points.cpu().numpy()  # Convert tensor to NumPy array if needed\n",
    "    edges = construct_edges(sas_np)\n",
    "    all_edges.append(torch.tensor(edges.T, dtype=torch.long))  # Convert to tensor\n",
    "\n",
    "# Print summary\n",
    "print(f\"Constructed edges for {len(all_edges)} graphs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3693f733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 251 out of 251 files successfully.\n",
      "Number of nodes: 1011\n",
      "Number of edges: 19479\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "from scipy.spatial.distance import euclidean\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Path to the directory containing PDB files\n",
    "pdb_dir = \"D:\\\\P2Rank_GNN_Dataset\\\\chen11\"\n",
    "\n",
    "# Get a list of all PDB files in the directory\n",
    "pdb_files = glob.glob(os.path.join(pdb_dir, \"*.pdb\"))\n",
    "\n",
    "\n",
    "def validate_and_fix_mol(mol):\n",
    "    \"\"\"\n",
    "    Removes atoms with invalid valences from the molecule.\n",
    "    \"\"\"\n",
    "    if mol is None:\n",
    "        return None\n",
    "    \n",
    "    to_remove = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        if atom.GetExplicitValence() > Chem.GetPeriodicTable().GetDefaultValence(atom.GetAtomicNum()):\n",
    "            to_remove.append(atom.GetIdx())\n",
    "\n",
    "    if to_remove:\n",
    "        editable_mol = Chem.EditableMol(mol)\n",
    "        for idx in sorted(to_remove, reverse=True):\n",
    "            editable_mol.RemoveAtom(idx)\n",
    "        return editable_mol.GetMol()\n",
    "    return mol\n",
    "\n",
    "\n",
    "def extract_sas_points(pdb_file):\n",
    "    \"\"\"\n",
    "    Extracts 3D coordinates for SAS points from a PDB file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mol = Chem.MolFromPDBFile(pdb_file, removeHs=False, sanitize=False)\n",
    "        if mol is None:\n",
    "            raise RuntimeError(f\"Failed to load PDB file: {pdb_file}\")\n",
    "\n",
    "        # Validate and fix problematic atoms\n",
    "        mol = validate_and_fix_mol(mol)\n",
    "        if mol is None:\n",
    "            raise RuntimeError(f\"Invalid molecule structure in {pdb_file}\")\n",
    "\n",
    "        # Attempt sanitization\n",
    "        Chem.SanitizeMol(mol)\n",
    "\n",
    "        # Extract 3D coordinates\n",
    "        conf = mol.GetConformer()\n",
    "        sas_points = np.array([[pos.x, pos.y, pos.z] for pos in (conf.GetAtomPosition(atom.GetIdx()) for atom in mol.GetAtoms())])\n",
    "\n",
    "        return sas_points if sas_points.size > 0 else None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing PDB file {pdb_file}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def construct_edges(sas_points, distance_threshold=6.0):\n",
    "    \"\"\"\n",
    "    Constructs edges based on spatial proximity between SAS points within a threshold.\n",
    "    \"\"\"\n",
    "    edges = []\n",
    "    num_points = len(sas_points)\n",
    "    for i in range(num_points):\n",
    "        for j in range(i + 1, num_points):\n",
    "            if euclidean(sas_points[i], sas_points[j]) < distance_threshold:\n",
    "                edges.append([i, j])\n",
    "    \n",
    "    return np.array(edges) if edges else np.empty((0, 2))\n",
    "\n",
    "\n",
    "# Process all PDB files\n",
    "all_node_features = []\n",
    "processed_files = 0\n",
    "\n",
    "for pdb_file in pdb_files:\n",
    "    sas_points = extract_sas_points(pdb_file)\n",
    "    if sas_points is not None:\n",
    "        # Convert SAS points to a torch tensor and store them\n",
    "        node_features = torch.tensor(sas_points, dtype=torch.float)\n",
    "        all_node_features.append(node_features)\n",
    "        processed_files += 1\n",
    "\n",
    "# Print summary of processed files\n",
    "print(f\"Processed {processed_files} out of {len(pdb_files)} files successfully.\")\n",
    "\n",
    "# Process the first valid PDB file as an example\n",
    "if all_node_features:\n",
    "    sas_points = all_node_features[0].numpy()  # Extract SAS points from the first molecule\n",
    "\n",
    "    # Construct edges based on proximity\n",
    "    edges = construct_edges(sas_points)\n",
    "\n",
    "    # Convert edge indices to torch tensor\n",
    "    edge_index = torch.tensor(edges.T, dtype=torch.long) if edges.size > 0 else torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "    # Compute edge features (Euclidean distance)\n",
    "    edge_features = torch.tensor([[euclidean(sas_points[i], sas_points[j])] for i, j in edges], dtype=torch.float).view(-1, 1) if edges.size > 0 else torch.empty((0, 1), dtype=torch.float)\n",
    "\n",
    "    # Example labels (dummy binding affinity or classification label)\n",
    "    labels = torch.full((len(sas_points),), 0.5, dtype=torch.float)  # Dummy labels for nodes\n",
    "\n",
    "    # Create the graph object using PyTorch Geometric\n",
    "    data = Data(x=torch.tensor(sas_points, dtype=torch.float),\n",
    "                edge_index=edge_index,\n",
    "                edge_attr=edge_features,\n",
    "                y=labels)\n",
    "\n",
    "    # Print the graph details\n",
    "    print(f'Number of nodes: {data.num_nodes}')\n",
    "    print(f'Number of edges: {data.num_edges}')\n",
    "else:\n",
    "    print(\"No valid node features were extracted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaeb8394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 2026\n",
      "Number of edges: 19479\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Example: Define edge features (distances between connected nodes)\n",
    "edge_features = torch.tensor(\n",
    "    np.linalg.norm(sas_points[edges[:, 0]] - sas_points[edges[:, 1]], axis=1).reshape(-1, 1),\n",
    "    dtype=torch.float\n",
    ")\n",
    "\n",
    "# Labels for the graph (example binding affinity or classification)\n",
    "# Here, using a single scalar as the label for the entire graph\n",
    "labels = torch.tensor([0.5], dtype=torch.float) \n",
    "\n",
    "# Create the graph object\n",
    "data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features, y=labels)\n",
    "\n",
    "# Print the graph details\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90890902",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of graphs: 251\n",
      "DataBatch(x=[2536, 3], edge_index=[2, 50553], edge_attr=[50553, 1], y=[2536], batch=[2536], ptr=[2])\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "from scipy.spatial.distance import euclidean\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Path to the directory containing PDB files\n",
    "pdb_dir = \"D:\\\\P2Rank_GNN_Dataset\\\\chen11\"\n",
    "\n",
    "# Get a list of all PDB files in the directory\n",
    "pdb_files = glob.glob(os.path.join(pdb_dir, \"*.pdb\"))\n",
    "\n",
    "def validate_and_fix_mol(mol):\n",
    "    to_remove = [atom.GetIdx() for atom in mol.GetAtoms()\n",
    "                 if atom.GetExplicitValence() > Chem.GetPeriodicTable().GetDefaultValence(atom.GetAtomicNum())]\n",
    "\n",
    "    if to_remove:\n",
    "        editable_mol = Chem.EditableMol(mol)\n",
    "        for idx in sorted(to_remove, reverse=True):\n",
    "            editable_mol.RemoveAtom(idx)\n",
    "        return editable_mol.GetMol()\n",
    "    return mol\n",
    "\n",
    "def extract_sas_points(pdb_file):\n",
    "    try:\n",
    "        mol = Chem.MolFromPDBFile(pdb_file, removeHs=False, sanitize=False)\n",
    "        if mol is None:\n",
    "            raise RuntimeError(f\"Failed to load PDB file: {pdb_file}\")\n",
    "\n",
    "        # Validate and fix problematic atoms\n",
    "        mol = validate_and_fix_mol(mol)\n",
    "        Chem.SanitizeMol(mol)\n",
    "\n",
    "        conf = mol.GetConformer()\n",
    "        sas_points = np.array([[pos.x, pos.y, pos.z] for pos in (conf.GetAtomPosition(atom.GetIdx()) for atom in mol.GetAtoms())])\n",
    "\n",
    "        return sas_points if sas_points.size > 0 else None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing PDB file {pdb_file}: {e}\")\n",
    "        return None\n",
    "\n",
    "def construct_edges(sas_points, distance_threshold=6.0):\n",
    "    edges = []\n",
    "    num_points = len(sas_points)\n",
    "    for i in range(num_points):\n",
    "        for j in range(i + 1, num_points):\n",
    "            if euclidean(sas_points[i], sas_points[j]) < distance_threshold:\n",
    "                edges.append([i, j])\n",
    "    \n",
    "    return np.array(edges) if edges else np.empty((0, 2))\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, pdb_files, transform=None, pre_transform=None):\n",
    "        super().__init__('.', transform, pre_transform)\n",
    "        self.pdb_files = pdb_files\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.pdb_files)\n",
    "\n",
    "    def get(self, idx):\n",
    "        pdb_file = self.pdb_files[idx]\n",
    "        sas_points = extract_sas_points(pdb_file)\n",
    "        if sas_points is None:\n",
    "            return None\n",
    "\n",
    "        edges = construct_edges(sas_points)\n",
    "        edge_index = torch.tensor(edges.T, dtype=torch.long) if edges.size > 0 else torch.empty((2, 0), dtype=torch.long)\n",
    "        edge_features = torch.tensor([[euclidean(sas_points[i], sas_points[j])] for i, j in edges], dtype=torch.float).view(-1, 1) if edges.size > 0 else torch.empty((0, 1), dtype=torch.float)\n",
    "\n",
    "        node_features = torch.tensor(sas_points, dtype=torch.float)\n",
    "        labels = torch.full((len(sas_points),), 0.5, dtype=torch.float)  \n",
    "\n",
    "        data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features, y=labels)\n",
    "        return data\n",
    "\n",
    "# Create the dataset and DataLoader\n",
    "protein_dataset = ProteinDataset(pdb_files)\n",
    "data_loader = DataLoader(protein_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Print summary of the dataset\n",
    "print(f\"Total number of graphs: {len(protein_dataset)}\")\n",
    "\n",
    "# Example of accessing a single graph data\n",
    "for data in data_loader:\n",
    "    print(data)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a190515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of graphs: 85\n",
      "DataBatch(x=[1758, 4], edge_index=[2, 34110], edge_attr=[34110, 1], y=[1758], batch=[1758], ptr=[2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-79f77642f73b>:99: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0]) if os.path.exists(self.processed_paths[0]) else self.process()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "from scipy.spatial import KDTree\n",
    "from torch_geometric.data import Data, InMemoryDataset, DataLoader\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Detect CUDA availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Path to the directory containing PDB files\n",
    "pdb_dir = \"D:\\\\P2Rank_GNN_Dataset\\\\chen11\"\n",
    "\n",
    "# Get a list of all PDB files in the directory\n",
    "pdb_files = glob.glob(os.path.join(pdb_dir, \"*.pdb\"))\n",
    "\n",
    "# ======================== Step 1: Validate and Fix Molecule ========================\n",
    "def validate_and_fix_mol(mol):\n",
    "    if mol is None:\n",
    "        return None\n",
    "    try:\n",
    "        for atom in mol.GetAtoms():\n",
    "            if atom.GetExplicitValence() > Chem.GetPeriodicTable().GetDefaultValence(atom.GetAtomicNum()):\n",
    "                return None  # Ignore molecules with incorrect valence\n",
    "        Chem.SanitizeMol(mol)\n",
    "        return mol\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# ======================== Step 2: Extract SAS Points Efficiently ========================\n",
    "def extract_sas_points(pdb_file):\n",
    "    mol = Chem.MolFromPDBFile(pdb_file, removeHs=False, sanitize=False)\n",
    "    mol = validate_and_fix_mol(mol)\n",
    "    if mol is None:\n",
    "        return None\n",
    "\n",
    "    conf = mol.GetConformer()\n",
    "    sas_points = np.array([[conf.GetAtomPosition(atom.GetIdx()).x,\n",
    "                            conf.GetAtomPosition(atom.GetIdx()).y,\n",
    "                            conf.GetAtomPosition(atom.GetIdx()).z] for atom in mol.GetAtoms()])\n",
    "    \n",
    "    return sas_points if sas_points.size > 0 else None\n",
    "\n",
    "# ======================== Step 3: Fast Edge Construction with KDTree ========================\n",
    "def construct_edges(sas_points, distance_threshold=6.0):\n",
    "    if len(sas_points) == 0:\n",
    "        return np.empty((0, 2), dtype=np.int64)\n",
    "\n",
    "    tree = KDTree(sas_points)\n",
    "    pairs = tree.query_pairs(distance_threshold)\n",
    "    edges = np.array(list(pairs))\n",
    "\n",
    "    return edges if edges.size > 0 else np.empty((0, 2), dtype=np.int64)\n",
    "\n",
    "# ======================== Step 5: Compute Local Graph Features Efficiently ========================\n",
    "def compute_local_graph_features(edges, num_nodes):\n",
    "    degree = np.zeros(num_nodes, dtype=np.float32)\n",
    "    for i, j in edges:\n",
    "        degree[i] += 1\n",
    "        degree[j] += 1\n",
    "    return torch.tensor(degree).view(-1, 1)  # Degree as node feature\n",
    "\n",
    "# ======================== Step 6: Parallel Graph Construction ========================\n",
    "def process_pdb_file(pdb_file):\n",
    "    sas_points = extract_sas_points(pdb_file)\n",
    "    if sas_points is None:\n",
    "        return None\n",
    "\n",
    "    edges = construct_edges(sas_points)\n",
    "    edge_index = torch.tensor(edges.T, dtype=torch.long) if edges.size > 0 else torch.empty((2, 0), dtype=torch.long)\n",
    "    edge_features = torch.tensor([[np.linalg.norm(sas_points[i] - sas_points[j])] for i, j in edges], dtype=torch.float) if edges.size > 0 else torch.empty((0, 1), dtype=torch.float)\n",
    "\n",
    "    # Node features: SAS points + Local graph features\n",
    "    node_features = torch.tensor(sas_points, dtype=torch.float)\n",
    "    local_graph_features = compute_local_graph_features(edges, len(sas_points))\n",
    "    \n",
    "    # Combine node features (coordinates + local properties)\n",
    "    combined_node_features = torch.cat([node_features, local_graph_features], dim=1)\n",
    "\n",
    "    labels = torch.full((len(sas_points),), 0.5, dtype=torch.float)  \n",
    "\n",
    "    data = Data(\n",
    "        x=combined_node_features.to(device),\n",
    "        edge_index=edge_index.to(device),\n",
    "        edge_attr=edge_features.to(device),\n",
    "        y=labels.to(device)\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "# ======================== Step 7: Optimized Dataset Class ========================\n",
    "class ProteinGraphDataset(InMemoryDataset):\n",
    "    def __init__(self, root, pdb_files, transform=None, pre_transform=None):\n",
    "        self.pdb_files = pdb_files\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0]) if os.path.exists(self.processed_paths[0]) else self.process()\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [\"protein_graphs.pt\"]\n",
    "\n",
    "    def process(self):\n",
    "        # Parallel Processing using Joblib\n",
    "        data_list = Parallel(n_jobs=8)(delayed(process_pdb_file)(pdb) for pdb in self.pdb_files)\n",
    "\n",
    "        # Remove None values (failed PDB files)\n",
    "        data_list = [d for d in data_list if d is not None]\n",
    "        print(f\"Processed {len(data_list)} graphs out of {len(self.pdb_files)} PDB files.\")\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "        return data, slices\n",
    "\n",
    "    def get(self, idx):\n",
    "        return super().get(idx)  # Corrected to use the parent class method\n",
    "\n",
    "# ======================== Step 8: Run Dataset Creation & DataLoader ========================\n",
    "protein_graph_dataset = ProteinGraphDataset(root='protein_data', pdb_files=pdb_files)\n",
    "dataset_loader = DataLoader(protein_graph_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "print(f\"Total number of graphs: {len(protein_graph_dataset)}\")\n",
    "\n",
    "# Example of accessing a single graph data\n",
    "for data in dataset_loader:\n",
    "    print(data)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca55a615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of graphs: 85\n",
      "DataBatch(x=[1242, 4], edge_index=[2, 23942], edge_attr=[23942, 1], y=[1242], batch=[1242], ptr=[2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-70e227797171>:104: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0]) if os.path.exists(self.processed_paths[0]) else self.process()\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "from scipy.spatial import KDTree\n",
    "from torch_geometric.data import Data, InMemoryDataset, DataLoader\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Detect CUDA availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Path to the directory containing PDB files\n",
    "pdb_dir = \"D:\\\\P2Rank_GNN_Dataset\\\\chen11\"\n",
    "\n",
    "# Get a list of all PDB files in the directory\n",
    "pdb_files = glob.glob(os.path.join(pdb_dir, \"*.pdb\"))\n",
    "\n",
    "# ======================== Step 1: Validate and Fix Molecule ========================\n",
    "def validate_and_fix_mol(mol):\n",
    "    if mol is None:\n",
    "        return None\n",
    "    try:\n",
    "        for atom in mol.GetAtoms():\n",
    "            if atom.GetExplicitValence() > Chem.GetPeriodicTable().GetDefaultValence(atom.GetAtomicNum()):\n",
    "                return None  # Ignore molecules with incorrect valence\n",
    "        Chem.SanitizeMol(mol)\n",
    "        return mol\n",
    "    except Exception as e:\n",
    "        print(f\"Error sanitizing molecule: {e}\")\n",
    "        return None\n",
    "\n",
    "# ======================== Step 2: Extract SAS Points Efficiently ========================\n",
    "def extract_sas_points(pdb_file):\n",
    "    try:\n",
    "        mol = Chem.MolFromPDBFile(pdb_file, removeHs=False, sanitize=False)\n",
    "        mol = validate_and_fix_mol(mol)\n",
    "        if mol is None:\n",
    "            return None\n",
    "\n",
    "        conf = mol.GetConformer()\n",
    "        sas_points = np.array([[conf.GetAtomPosition(atom.GetIdx()).x,\n",
    "                                conf.GetAtomPosition(atom.GetIdx()).y,\n",
    "                                conf.GetAtomPosition(atom.GetIdx()).z] for atom in mol.GetAtoms()])\n",
    "        \n",
    "        return sas_points if sas_points.size > 0 else None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing PDB file {pdb_file}: {e}\")\n",
    "        return None\n",
    "\n",
    "# ======================== Step 3: Fast Edge Construction with KDTree ========================\n",
    "def construct_edges(sas_points, distance_threshold=6.0):\n",
    "    if len(sas_points) == 0:\n",
    "        return np.empty((0, 2), dtype=np.int64)\n",
    "\n",
    "    tree = KDTree(sas_points)\n",
    "    pairs = tree.query_pairs(distance_threshold)\n",
    "    edges = np.array(list(pairs))\n",
    "\n",
    "    return edges if edges.size > 0 else np.empty((0, 2), dtype=np.int64)\n",
    "\n",
    "# ======================== Step 5: Compute Local Graph Features Efficiently ========================\n",
    "def compute_local_graph_features(edges, num_nodes):\n",
    "    degree = np.zeros(num_nodes, dtype=np.float32)\n",
    "    for i, j in edges:\n",
    "        degree[i] += 1\n",
    "        degree[j] += 1\n",
    "    return torch.tensor(degree).view(-1, 1)  # Degree as node feature\n",
    "\n",
    "# ======================== Step 6: Parallel Graph Construction ========================\n",
    "def process_pdb_file(pdb_file):\n",
    "    sas_points = extract_sas_points(pdb_file)\n",
    "    if sas_points is None:\n",
    "        return None\n",
    "\n",
    "    edges = construct_edges(sas_points)\n",
    "    edge_index = torch.tensor(edges.T, dtype=torch.long) if edges.size > 0 else torch.empty((2, 0), dtype=torch.long)\n",
    "    edge_features = torch.tensor([[np.linalg.norm(sas_points[i] - sas_points[j])] for i, j in edges], dtype=torch.float) if edges.size > 0 else torch.empty((0, 1), dtype=torch.float)\n",
    "\n",
    "    # Node features: SAS points + Local graph features\n",
    "    node_features = torch.tensor(sas_points, dtype=torch.float)\n",
    "    local_graph_features = compute_local_graph_features(edges, len(sas_points))\n",
    "    \n",
    "    # Combine node features (coordinates + local properties)\n",
    "    combined_node_features = torch.cat([node_features, local_graph_features], dim=1)\n",
    "\n",
    "    labels = torch.full((len(sas_points),), 0.5, dtype=torch.float)  \n",
    "\n",
    "    data = Data(\n",
    "        x=combined_node_features.to(device),\n",
    "        edge_index=edge_index.to(device),\n",
    "        edge_attr=edge_features.to(device),\n",
    "        y=labels.to(device)\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "# ======================== Step 7: Optimized Dataset Class ========================\n",
    "class ProteinGraphDataset(InMemoryDataset):\n",
    "    def __init__(self, root, pdb_files, transform=None, pre_transform=None):\n",
    "        self.pdb_files = pdb_files\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0]) if os.path.exists(self.processed_paths[0]) else self.process()\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [\"protein_graphs.pt\"]\n",
    "\n",
    "    def process(self):\n",
    "        # Parallel Processing using Joblib\n",
    "        data_list = Parallel(n_jobs=8)(delayed(process_pdb_file)(pdb) for pdb in self.pdb_files)\n",
    "\n",
    "        # Remove None values (failed PDB files)\n",
    "        data_list = [d for d in data_list if d is not None]\n",
    "        print(f\"Processed {len(data_list)} graphs out of {len(self.pdb_files)} PDB files.\")\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "        return data, slices\n",
    "\n",
    "    def get(self, idx):\n",
    "        return super().get(idx)  # Corrected to use the parent class method\n",
    "\n",
    "# ======================== Step 8: Run Dataset Creation & DataLoader ========================\n",
    "protein_graph_dataset = ProteinGraphDataset(root='protein_data', pdb_files=pdb_files)\n",
    "dataset_loader = DataLoader(protein_graph_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "print(f\"Total number of graphs: {len(protein_graph_dataset)}\")\n",
    "\n",
    "# Example of accessing a single graph data\n",
    "for data in dataset_loader:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd304b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of graphs: 85\n",
      "DataBatch(x=[1782, 4], edge_index=[2, 35004], edge_attr=[35004, 1], y=[1782], batch=[1782], ptr=[2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-1ab78ff41046>:112: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0]) if os.path.exists(self.processed_paths[0]) else self.process()\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "from torch_geometric.data import Data, InMemoryDataset, DataLoader\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "# Detect CUDA availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Path to the directory containing PDB files\n",
    "pdb_dir = \"D:\\\\P2Rank_GNN_Dataset\\\\chen11\"\n",
    "\n",
    "# Get a list of all PDB files in the directory\n",
    "pdb_files = glob.glob(os.path.join(pdb_dir, \"*.pdb\"))\n",
    "\n",
    "def validate_and_fix_mol(mol):\n",
    "    if mol is None:\n",
    "        return None\n",
    "    try:\n",
    "        for atom in mol.GetAtoms():\n",
    "            if atom.GetExplicitValence() > Chem.GetPeriodicTable().GetDefaultValence(atom.GetAtomicNum()):\n",
    "                return None  # Ignore molecules with incorrect valence\n",
    "        Chem.SanitizeMol(mol)\n",
    "        return mol\n",
    "    except Exception as e:\n",
    "        print(f\"Error sanitizing molecule: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_sas_points(pdb_file):\n",
    "    try:\n",
    "        mol = Chem.MolFromPDBFile(pdb_file, removeHs=False, sanitize=False)\n",
    "        mol = validate_and_fix_mol(mol)\n",
    "        if mol is None:\n",
    "            return None\n",
    "\n",
    "        # Compute Gasteiger partial charges\n",
    "        Chem.rdPartialCharges.ComputeGasteigerCharges(mol)\n",
    "\n",
    "        conf = mol.GetConformer()\n",
    "        sas_points = np.array([[conf.GetAtomPosition(atom.GetIdx()).x,\n",
    "                                conf.GetAtomPosition(atom.GetIdx()).y,\n",
    "                                conf.GetAtomPosition(atom.GetIdx()).z] for atom in mol.GetAtoms()])\n",
    "        \n",
    "        return mol, sas_points if sas_points.size > 0 else None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing PDB file {pdb_file}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def construct_edges(sas_points, distance_threshold=6.0):\n",
    "    if len(sas_points) == 0:\n",
    "        return np.empty((0, 2), dtype=np.int64)\n",
    "\n",
    "    tree = KDTree(sas_points)\n",
    "    pairs = tree.query_pairs(distance_threshold)\n",
    "    edges = np.array(list(pairs))\n",
    "\n",
    "    return edges if edges.size > 0 else np.empty((0, 2), dtype=np.int64)\n",
    "\n",
    "def compute_atomic_features(mol, sas_points, radius=6.0):\n",
    "    atomic_features = []\n",
    "    for sas_point in sas_points:\n",
    "        nearby_atoms = []\n",
    "        for atom in mol.GetAtoms():\n",
    "            pos = mol.GetConformer().GetAtomPosition(atom.GetIdx())\n",
    "            dist = np.linalg.norm(np.array([pos.x, pos.y, pos.z]) - sas_point)\n",
    "            if dist <= radius:\n",
    "                atomic_num = atom.GetAtomicNum()\n",
    "                aromatic = int(atom.GetIsAromatic())\n",
    "                hybridization = int(atom.GetHybridization())\n",
    "                degree = atom.GetDegree()\n",
    "                partial_charge = atom.GetDoubleProp('_GasteigerCharge')\n",
    "                nearby_atoms.append([atomic_num, aromatic, hybridization, degree, partial_charge])\n",
    "        \n",
    "        if nearby_atoms:\n",
    "            atomic_features.append(np.mean(nearby_atoms, axis=0))\n",
    "        else:\n",
    "            atomic_features.append(np.zeros(5))\n",
    "    \n",
    "    return torch.tensor(atomic_features, dtype=torch.float)\n",
    "\n",
    "def process_pdb_file(pdb_file):\n",
    "    mol, sas_points = extract_sas_points(pdb_file)\n",
    "    if sas_points is None:\n",
    "        return None\n",
    "\n",
    "    edges = construct_edges(sas_points)\n",
    "    edge_index = torch.tensor(edges.T, dtype=torch.long) if edges.size > 0 else torch.empty((2, 0), dtype=torch.long)\n",
    "    edge_features = torch.tensor([[np.linalg.norm(sas_points[i] - sas_points[j])] for i, j in edges], dtype=torch.float) if edges.size > 0 else torch.empty((0, 1), dtype=torch.float)\n",
    "\n",
    "    # Node features: Atomic features\n",
    "    node_features = compute_atomic_features(mol, sas_points)\n",
    "    \n",
    "    labels = torch.full((len(sas_points),), 0.5, dtype=torch.float)  \n",
    "\n",
    "    data = Data(\n",
    "        x=node_features.to(device),\n",
    "        edge_index=edge_index.to(device),\n",
    "        edge_attr=edge_features.to(device),\n",
    "        y=labels.to(device)\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "class ProteinGraphDataset(InMemoryDataset):\n",
    "    def __init__(self, root, pdb_files, transform=None, pre_transform=None):\n",
    "        self.pdb_files = pdb_files\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0]) if os.path.exists(self.processed_paths[0]) else self.process()\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [\"protein_graphs.pt\"]\n",
    "\n",
    "    def process(self):\n",
    "        data_list = Parallel(n_jobs=8)(delayed(process_pdb_file)(pdb) for pdb in self.pdb_files)\n",
    "        data_list = [d for d in data_list if d is not None]\n",
    "        print(f\"Processed {len(data_list)} graphs out of {len(self.pdb_files)} PDB files.\")\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "        return data, slices\n",
    "\n",
    "    def get(self, idx):\n",
    "        return super().get(idx)\n",
    "\n",
    "protein_graph_dataset = ProteinGraphDataset(root='protein_data', pdb_files=pdb_files)\n",
    "dataset_loader = DataLoader(protein_graph_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "print(f\"Total number of graphs: {len(protein_graph_dataset)}\")\n",
    "\n",
    "for data in dataset_loader:\n",
    "    print(data)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5363a800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degrees: {266: 53, 268: 50, 400: 38, 1022: 52, 928: 56, 1141: 55, 298: 42, 745: 47, 1447: 29, 1706: 57, 490: 49, 915: 43, 1620: 33, 1634: 39, 1257: 48, 1582: 46, 4: 38, 1961: 48, 1220: 47, 1700: 46, 1256: 50, 1357: 42, 129: 39, 155: 24, 561: 46, 566: 28, 1421: 39, 1424: 37, 44: 34, 47: 24, 904: 52, 905: 54, 1115: 41, 1125: 36, 1975: 47, 1983: 52, 619: 48, 921: 62, 273: 44, 284: 45, 1138: 56, 1486: 57, 1133: 44, 1142: 47, 1458: 30, 1464: 29, 424: 38, 453: 29, 1229: 50, 1604: 56, 1671: 39, 1757: 42, 1344: 49, 1362: 45, 1476: 12, 1481: 49, 1687: 38, 1701: 46, 99: 36, 104: 54, 442: 22, 443: 16, 1488: 48, 1491: 49, 254: 23, 392: 40, 419: 54, 459: 49, 1339: 48, 1368: 24, 971: 33, 972: 43, 671: 48, 680: 53, 1183: 52, 1794: 33, 1375: 42, 1964: 43, 1543: 34, 1548: 31, 166: 29, 171: 33, 245: 52, 464: 46, 1026: 31, 1029: 31, 1886: 46, 1887: 45, 1977: 52, 2005: 45, 449: 34, 614: 51, 2024: 34, 509: 57, 510: 51, 593: 47, 1147: 43, 1328: 47, 1367: 27, 1352: 47, 1953: 45, 1309: 46, 1317: 53, 1231: 52, 1434: 37, 186: 53, 234: 53, 637: 54, 695: 54, 1863: 50, 1876: 43, 1321: 48, 1327: 46, 161: 45, 177: 53, 1081: 53, 1086: 29, 1664: 48, 1666: 56, 504: 49, 516: 43, 564: 54, 567: 22, 163: 37, 223: 29, 1425: 30, 1550: 28, 1564: 26, 1875: 37, 947: 55, 2025: 40, 584: 40, 1973: 47, 1033: 36, 1045: 37, 1093: 30, 1096: 19, 1194: 56, 1902: 43, 1151: 56, 1266: 44, 34: 38, 752: 54, 526: 26, 600: 51, 1163: 42, 643: 36, 1799: 30, 216: 40, 276: 38, 285: 37, 667: 44, 1527: 35, 1553: 38, 575: 50, 1106: 45, 1719: 33, 1723: 21, 1088: 50, 1102: 28, 1948: 47, 1960: 47, 511: 44, 532: 28, 1731: 31, 1733: 24, 631: 56, 634: 52, 1492: 54, 1587: 46, 1954: 48, 479: 56, 994: 54, 1970: 52, 399: 35, 476: 52, 1925: 49, 1949: 54, 397: 49, 403: 42, 1383: 53, 1400: 28, 1443: 36, 1451: 40, 283: 46, 301: 54, 926: 53, 932: 49, 1805: 35, 2032: 46, 1786: 41, 1790: 42, 1937: 51, 1959: 53, 409: 21, 413: 42, 92: 50, 706: 42, 235: 54, 260: 46, 427: 29, 430: 41, 1182: 54, 2026: 39, 1287: 44, 1288: 39, 605: 50, 702: 57, 388: 31, 475: 47, 1649: 38, 1677: 51, 1267: 45, 1575: 49, 978: 36, 1472: 17, 121: 41, 131: 26, 938: 49, 981: 48, 989: 57, 577: 52, 1128: 53, 1841: 42, 1847: 32, 1781: 51, 1796: 40, 404: 41, 470: 32, 307: 27, 486: 44, 482: 45, 487: 47, 1270: 51, 2031: 34, 1493: 47, 1514: 54, 56: 55, 86: 43, 176: 52, 188: 49, 2042: 19, 613: 58, 943: 60, 360: 53, 497: 57, 1896: 53, 1904: 50, 826: 39, 1990: 42, 1619: 24, 1626: 17, 1505: 41, 1524: 52, 677: 47, 1867: 46, 1623: 43, 1745: 54, 1848: 40, 1350: 43, 1586: 44, 603: 59, 821: 32, 1996: 43, 1635: 34, 1755: 46, 1674: 51, 1683: 23, 1390: 43, 1924: 51, 1500: 35, 1530: 27, 832: 18, 842: 40, 32: 36, 35: 42, 2017: 55, 2022: 26, 983: 47, 1011: 51, 315: 45, 323: 49, 2029: 33, 995: 52, 1021: 49, 869: 42, 882: 51, 948: 51, 1175: 48, 1915: 52, 1930: 55, 327: 53, 333: 38, 1187: 48, 1191: 53, 1756: 48, 1398: 31, 1411: 30, 670: 48, 672: 51, 1016: 35, 1153: 48, 1580: 44, 841: 49, 1171: 50, 1597: 38, 1892: 58, 1919: 28, 462: 48, 908: 52, 382: 41, 390: 29, 1242: 54, 1248: 51, 725: 50, 729: 49, 876: 37, 898: 41, 1392: 40, 1946: 52, 1807: 40, 208: 35, 210: 27, 719: 47, 914: 46, 1254: 47, 1258: 46, 739: 49, 1850: 28, 2043: 16, 737: 54, 363: 47, 498: 52, 437: 21, 447: 46, 857: 41, 160: 41, 169: 20, 1020: 53, 1027: 34, 1880: 38, 1885: 44, 1247: 43, 988: 54, 1489: 58, 587: 49, 1145: 49, 263: 45, 267: 53, 1: 30, 1987: 48, 792: 30, 796: 32, 1193: 51, 1894: 53, 1652: 30, 1654: 33, 1234: 46, 1895: 58, 181: 39, 642: 48, 599: 48, 1155: 57, 1743: 47, 1772: 26, 1592: 53, 1603: 55, 215: 44, 226: 34, 275: 43, 277: 35, 1075: 35, 1084: 31, 426: 24, 446: 41, 598: 52, 930: 50, 755: 42, 1354: 50, 1438: 50, 199: 40, 632: 51, 1087: 54, 1094: 29, 1947: 52, 1952: 47, 1188: 44, 1900: 48, 1710: 33, 138: 47, 164: 42, 570: 48, 998: 45, 1430: 32, 1433: 40, 1190: 49, 1192: 47, 1984: 52, 1992: 38, 282: 42, 293: 45, 359: 49, 513: 52, 1224: 39, 1715: 29, 190: 48, 704: 57, 625: 50, 1485: 54, 1490: 55, 1237: 42, 1388: 42, 1696: 37, 968: 33, 1126: 40, 1557: 48, 1828: 60, 1829: 55, 2014: 49, 2019: 34, 1673: 59, 1726: 39, 126: 41, 130: 29, 1197: 53, 1208: 42, 689: 51, 1251: 42, 1444: 35, 242: 44, 463: 46, 1023: 44, 1028: 34, 1176: 52, 140: 54, 1000: 51, 1044: 22, 1506: 44, 332: 44, 356: 38, 1556: 46, 1552: 36, 975: 47, 987: 28, 1035: 41, 1038: 35, 1835: 48, 1845: 35, 1573: 45, 735: 47, 746: 47, 1265: 44, 193: 54, 197: 48, 518: 38, 519: 46, 602: 61, 1156: 58, 1204: 41, 1622: 39, 1737: 52, 1355: 44, 1393: 43, 1855: 52, 687: 49, 705: 50, 272: 49, 1474: 27, 230: 46, 237: 48, 1950: 47, 525: 26, 766: 50, 421: 49, 936: 52, 591: 42, 1429: 29, 1692: 45, 314: 40, 742: 53, 762: 45, 1962: 46, 1963: 44, 535: 34, 1385: 46, 1728: 25, 1732: 33, 1196: 49, 1871: 50, 26: 48, 33: 30, 369: 28, 372: 34, 665: 44, 1440: 37, 1450: 41, 731: 46, 761: 50, 63: 49, 73: 41, 923: 57, 931: 47, 381: 38, 1820: 41, 1856: 52, 232: 54, 259: 41, 1092: 38, 1117: 48, 1152: 48, 1168: 43, 692: 50, 1225: 58, 1646: 57, 1211: 44, 1748: 55, 953: 33, 958: 40, 1278: 17, 1280: 38, 175: 49, 664: 44, 1522: 41, 436: 26, 439: 17, 1296: 34, 1297: 38, 1507: 47, 1517: 51, 727: 54, 94: 46, 675: 50, 1342: 49, 990: 55, 1602: 52, 1754: 56, 1239: 43, 1702: 47, 148: 29, 157: 22, 1579: 53, 244: 48, 1216: 43, 1718: 32, 431: 33, 445: 34, 1214: 52, 1645: 55, 491: 42, 496: 53, 716: 52, 834: 8, 835: 8, 125: 41, 146: 35, 985: 32, 1004: 29, 684: 54, 1830: 54, 506: 38, 85: 43, 747: 46, 1346: 46, 143: 40, 1363: 39, 1364: 42, 1343: 51, 1533: 40, 853: 55, 2016: 55, 1178: 59, 1584: 49, 925: 53, 546: 35, 553: 37, 269: 45, 697: 55, 722: 53, 1129: 46, 1199: 57, 1872: 52, 29: 38, 1509: 43, 1539: 24, 1143: 51, 851: 45, 41: 46, 901: 57, 902: 54, 1376: 35, 744: 53, 918: 50, 324: 51, 552: 25, 1395: 33, 1410: 34, 1185: 50, 1600: 53, 861: 51, 326: 48, 378: 51, 1713: 37, 1200: 50, 36: 40, 50: 49, 96: 45, 101: 26, 247: 50, 270: 50, 679: 53, 681: 56, 440: 24, 1750: 55, 1759: 53, 1180: 55, 1606: 55, 999: 51, 1036: 42, 589: 49, 1059: 37, 331: 52, 348: 44, 542: 39, 568: 14, 760: 45, 674: 48, 734: 47, 738: 54, 42: 27, 1908: 43, 1594: 44, 1596: 40, 183: 54, 635: 40, 563: 56, 856: 42, 217: 30, 219: 21, 771: 51, 805: 34, 53: 31, 754: 46, 903: 51, 924: 52, 1782: 47, 1832: 49, 194: 53, 236: 46, 456: 49, 1306: 28, 1314: 44, 789: 51, 795: 35, 1245: 53, 178: 45, 641: 38, 940: 51, 964: 35, 98: 43, 123: 41, 1318: 50, 1324: 34, 657: 34, 10: 33, 693: 50, 2028: 39, 801: 23, 1661: 43, 1663: 26, 501: 51, 1801: 31, 224: 33, 286: 34, 1512: 50, 1540: 20, 1295: 33, 1313: 45, 192: 52, 302: 52, 303: 45, 1640: 56, 1725: 39, 1519: 49, 736: 49, 1956: 49, 811: 28, 1656: 35, 1669: 45, 1716: 28, 1720: 40, 1170: 45, 980: 54, 1007: 50, 1031: 46, 1439: 45, 1442: 46, 1139: 55, 1150: 58, 1201: 59, 996: 52, 1290: 45, 1319: 48, 80: 47, 82: 45, 1253: 49, 1437: 34, 1160: 55, 1002: 42, 1037: 40, 1494: 48, 1499: 36, 334: 33, 349: 34, 1034: 48, 1837: 30, 1838: 32, 863: 44, 878: 61, 1685: 20, 135: 52, 139: 41, 997: 54, 945: 41, 1934: 48, 346: 33, 1146: 46, 1166: 44, 46: 33, 67: 38, 1340: 44, 1971: 56, 1386: 52, 686: 55, 1181: 59, 698: 54, 1549: 27, 816: 39, 707: 52, 715: 56, 330: 50, 765: 52, 1032: 41, 58: 52, 77: 47, 574: 48, 1009: 56, 1053: 39, 1501: 40, 1515: 55, 1217: 55, 1561: 42, 1566: 42, 1223: 43, 1261: 48, 1274: 25, 894: 44, 1905: 52, 1255: 42, 1459: 28, 202: 34, 206: 44, 1062: 34, 1064: 43, 1273: 31, 1284: 35, 1695: 28, 39: 30, 696: 57, 714: 59, 823: 37, 1616: 40, 828: 31, 833: 11, 179: 44, 195: 47, 1039: 35, 65: 44, 93: 42, 212: 34, 257: 44, 927: 53, 540: 43, 551: 21, 751: 48, 481: 45, 910: 46, 23: 41, 580: 41, 889: 51, 1394: 33, 1402: 33, 1639: 51, 895: 42, 900: 52, 1758: 41, 655: 28, 659: 43, 1120: 48, 1906: 47, 1927: 50, 1238: 44, 1449: 38, 607: 59, 618: 51, 25: 44, 362: 48, 787: 48, 30: 38, 48: 42, 1678: 41, 90: 49, 950: 49, 957: 49, 1161: 52, 1177: 55, 433: 32, 438: 21, 1479: 46, 410: 20, 454: 27, 1504: 36, 1516: 46, 929: 52, 1019: 55, 962: 30, 967: 29, 1822: 27, 1825: 52, 299: 44, 623: 39, 448: 33, 1236: 44, 1305: 42, 911: 48, 296: 45, 325: 52, 1460: 46, 1611: 40, 1763: 52, 97: 45, 115: 45, 489: 47, 1877: 49, 1882: 35, 500: 52, 505: 44, 783: 51, 793: 46, 843: 37, 844: 33, 521: 42, 628: 50, 690: 49, 134: 54, 1889: 23, 669: 48, 691: 51, 1378: 32, 1942: 45, 3: 13, 1312: 48, 1322: 40, 803: 28, 1655: 35, 555: 41, 562: 47, 713: 54, 1866: 40, 1881: 30, 1538: 25, 1998: 38, 2000: 33, 38: 39, 43: 35, 512: 40, 865: 44, 1446: 31, 1672: 29, 1427: 39, 1599: 35, 341: 26, 1613: 48, 1785: 46, 1722: 30, 1205: 38, 1209: 50, 455: 34, 45: 37, 59: 48, 105: 42, 110: 20, 917: 52, 1107: 44, 965: 27, 1826: 49, 1380: 33, 1916: 49, 1944: 37, 398: 38, 1857: 50, 351: 36, 573: 44, 1008: 49, 1260: 49, 743: 48, 1605: 49, 764: 51, 522: 38, 112: 47, 590: 46, 984: 42, 465: 45, 1293: 32, 1272: 36, 460: 52, 1006: 15, 750: 52, 763: 44, 1978: 50, 450: 40, 471: 26, 1670: 36, 944: 51, 979: 40, 311: 40, 312: 36, 1382: 51, 594: 49, 711: 53, 650: 29, 871: 46, 1665: 57, 1729: 32, 492: 42, 2008: 40, 673: 56, 366: 33, 89: 50, 91: 48, 860: 56, 877: 41, 576: 46, 1118: 43, 189: 49, 1735: 44, 13: 30, 610: 50, 1503: 41, 1508: 45, 515: 40, 1329: 43, 661: 51, 1144: 54, 730: 47, 1935: 52, 1558: 42, 1565: 30, 1384: 52, 1412: 30, 724: 55, 1843: 31, 1218: 48, 1874: 40, 1787: 32, 1802: 29, 205: 37, 1063: 39, 520: 35, 785: 48, 544: 33, 728: 46, 1913: 54, 1914: 58, 1571: 50, 483: 45, 151: 31, 1071: 37, 1073: 16, 781: 54, 1162: 47, 1484: 51, 1361: 12, 503: 50, 1169: 50, 1581: 53, 1625: 21, 1632: 34, 1186: 52, 790: 47, 31: 44, 1910: 40, 748: 54, 770: 53, 1066: 24, 1079: 46, 1130: 49, 1986: 43, 1988: 41, 1591: 53, 384: 24, 493: 45, 549: 38, 560: 19, 676: 45, 1833: 41, 609: 56, 611: 56, 1951: 50, 361: 53, 780: 49, 627: 48, 778: 49, 797: 30, 1428: 42, 622: 44, 51: 48, 909: 47, 1764: 50, 1767: 40, 807: 29, 668: 48, 1766: 59, 1235: 47, 1423: 45, 1252: 49, 288: 42, 87: 48, 1468: 17, 616: 54, 678: 52, 108: 24, 1778: 34, 1823: 27, 1819: 31, 1824: 43, 1302: 35, 294: 47, 402: 33, 1048: 29, 1279: 36, 1315: 47, 154: 32, 165: 26, 653: 31, 1798: 35, 920: 57, 1968: 24, 1891: 50, 726: 53, 741: 52, 2009: 40, 514: 44, 527: 23, 531: 19, 852: 50, 238: 52, 1123: 31, 1316: 48, 12: 26, 1202: 57, 1609: 48, 1090: 40, 571: 49, 227: 22, 1547: 42, 1286: 39, 1495: 55, 1049: 35, 1768: 33, 733: 45, 757: 47, 1893: 57, 1907: 44, 756: 44, 824: 49, 875: 40, 69: 31, 1643: 63, 1167: 42, 1095: 25, 648: 32, 649: 32, 890: 51, 1727: 36, 79: 53, 1865: 47, 495: 46, 592: 46, 885: 33, 539: 38, 864: 50, 367: 37, 1638: 29, 1738: 40, 1371: 50, 1496: 44, 703: 52, 422: 49, 854: 48, 1116: 36, 1974: 54, 407: 33, 1404: 33, 1083: 42, 1112: 19, 415: 44, 1574: 53, 683: 56, 1502: 45, 1932: 46, 49: 47, 74: 47, 710: 42, 1928: 46, 434: 37, 1292: 41, 1612: 43, 1614: 45, 1765: 49, 773: 44, 1630: 11, 1631: 10, 61: 44, 84: 51, 942: 54, 993: 62, 891: 50, 1851: 22, 253: 27, 701: 66, 1800: 32, 423: 36, 474: 53, 290: 43, 321: 20, 1518: 44, 825: 45, 830: 32, 976: 46, 1703: 50, 1338: 49, 837: 44, 840: 47, 1749: 58, 1697: 38, 1698: 35, 191: 45, 320: 28, 55: 25, 804: 31, 20: 39, 1831: 50, 1056: 43, 1463: 26, 1467: 19, 814: 19, 829: 34, 1164: 44, 1585: 44, 758: 49, 897: 41, 1704: 53, 912: 45, 1475: 31, 1477: 33, 375: 25, 1326: 45, 255: 44, 886: 25, 1693: 38, 585: 45, 1127: 44, 1195: 53, 265: 51, 1534: 34, 788: 48, 946: 55, 1483: 49, 153: 25, 1013: 30, 1015: 25, 774: 45, 394: 40, 368: 40, 480: 52, 1811: 32, 214: 34, 1068: 32, 1072: 25, 1601: 52, 239: 49, 466: 39, 620: 44, 1080: 45, 1082: 46, 720: 48, 1149: 43, 271: 47, 1903: 44, 106: 45, 287: 28, 1991: 30, 606: 54, 1709: 56, 800: 27, 1607: 49, 1658: 20, 1135: 52, 1418: 39, 318: 41, 328: 49, 769: 49, 2012: 46, 636: 44, 28: 40, 78: 51, 117: 45, 1165: 41, 478: 49, 1773: 24, 1776: 15, 626: 54, 472: 51, 1659: 32, 1535: 32, 174: 45, 344: 31, 604: 55, 337: 39, 354: 50, 1372: 47, 1967: 38, 231: 56, 1480: 42, 963: 23, 1366: 37, 1751: 52, 991: 55, 1849: 37, 1577: 47, 1595: 49, 1608: 47, 201: 31, 1746: 47, 1777: 26, 1381: 26, 536: 37, 1397: 27, 1396: 28, 19: 29, 21: 41, 776: 37, 1099: 33, 1957: 51, 1510: 46, 529: 41, 1373: 43, 1387: 45, 1617: 31, 1747: 41, 1276: 21, 1454: 31, 319: 40, 401: 43, 473: 51, 14: 34, 27: 48, 934: 56, 935: 49, 225: 36, 1025: 41, 1054: 36, 1567: 44, 1736: 46, 1993: 47, 412: 46, 1012: 41, 1860: 41, 2040: 21, 712: 55, 1241: 51, 1244: 47, 81: 49, 141: 55, 145: 44, 1979: 43, 1752: 53, 767: 51, 772: 43, 1264: 41, 1578: 52, 11: 34, 250: 39, 1301: 23, 633: 48, 779: 50, 782: 46, 1024: 37, 262: 48, 113: 50, 357: 52, 721: 52, 376: 48, 906: 58, 317: 40, 52: 43, 167: 23, 629: 58, 1707: 57, 557: 34, 279: 30, 1989: 33, 1995: 48, 1268: 39, 896: 44, 364: 48, 377: 34, 2001: 40, 1761: 43, 1912: 48, 1933: 50, 336: 33, 387: 35, 1335: 44, 1414: 22, 533: 33, 1939: 51, 444: 31, 1299: 24, 1610: 48, 1233: 48, 1436: 45, 1780: 50, 60: 51, 111: 50, 951: 45, 969: 31, 1077: 37, 240: 52, 1148: 42, 578: 44, 579: 43, 2021: 26, 799: 32, 70: 23, 1657: 35, 1740: 22, 1775: 23, 1132: 48, 127: 46, 461: 52, 933: 54, 297: 50, 1667: 54, 1323: 38, 2004: 44, 2006: 43, 645: 42, 646: 32, 1554: 39, 1724: 29, 207: 41, 420: 51, 1103: 24, 1154: 59, 1999: 39, 1784: 42, 1858: 46, 1441: 42, 700: 64, 1560: 36, 425: 37, 184: 53, 1041: 35, 274: 42, 353: 45, 1570: 47, 1842: 26, 1001: 46, 949: 49, 1859: 50, 1407: 39, 1899: 50, 1869: 51, 1431: 29, 1689: 36, 304: 48, 708: 55, 16: 22, 380: 34, 1405: 30, 1198: 60, 1868: 50, 1688: 37, 688: 47, 1057: 44, 1862: 48, 2033: 34, 775: 37, 2044: 16, 83: 41, 256: 44, 252: 35, 1931: 48, 144: 51, 1089: 43, 1926: 44, 1792: 38, 2013: 51, 103: 53, 1010: 51, 1810: 39, 1300: 22, 1330: 39, 1250: 44, 1705: 57, 1310: 48, 1349: 46, 329: 42, 855: 53, 1648: 43, 1598: 34, 639: 42, 119: 51, 883: 46, 831: 24, 838: 42, 982: 50, 200: 32, 850: 17, 848: 20, 7: 26, 484: 47, 1770: 26, 345: 31, 417: 46, 1789: 38, 411: 20, 1513: 49, 1779: 44, 182: 52, 1861: 49, 406: 33, 595: 48, 880: 51, 485: 46, 1050: 28, 180: 52, 638: 54, 1219: 50, 40: 36, 1836: 33, 1173: 50, 1303: 38, 768: 55, 1621: 33, 1846: 34, 1104: 38, 588: 43, 798: 22, 808: 27, 1615: 35, 1943: 47, 1370: 48, 1744: 52, 2015: 45, 660: 45, 316: 43, 1174: 51, 1189: 51, 654: 36, 1682: 30, 937: 48, 1559: 32, 373: 40, 1809: 48, 709: 51, 1184: 53, 1569: 46, 1739: 32, 132: 44, 142: 48, 1406: 44, 1864: 44, 1347: 44, 545: 29, 846: 35, 1806: 37, 209: 31, 1067: 28, 548: 41, 1091: 45, 1544: 29, 887: 30, 494: 44, 507: 34, 1365: 38, 1416: 15, 1114: 44, 1124: 26, 1435: 29, 1134: 49, 1941: 50, 615: 62, 959: 52, 309: 42, 892: 44, 952: 38, 954: 26, 867: 43, 970: 36, 919: 51, 1432: 33, 261: 50, 451: 45, 621: 48, 1675: 46, 1699: 25, 102: 45, 1215: 54, 1714: 25, 441: 20, 1853: 46, 339: 33, 1536: 23, 647: 39, 1997: 45, 1230: 55, 159: 36, 1647: 49, 1721: 42, 1325: 34, 597: 43, 1545: 31, 305: 35, 338: 28, 1936: 43, 508: 37, 815: 37, 817: 35, 847: 26, 1228: 51, 1712: 27, 1562: 40, 870: 46, 874: 49, 1730: 37, 457: 52, 355: 47, 524: 30, 868: 41, 1304: 45, 1331: 27, 468: 33, 1269: 47, 1076: 39, 1100: 32, 408: 35, 558: 24, 1110: 36, 1521: 51, 1563: 34, 1568: 42, 879: 56, 1046: 32, 72: 43, 9: 28, 428: 26, 1058: 44, 109: 22, 2035: 29, 241: 45, 248: 45, 1172: 44, 777: 53, 1583: 51, 1994: 42, 1113: 42, 17: 24, 992: 53, 596: 43, 1917: 41, 383: 28, 1003: 38, 264: 55, 651: 21, 1753: 57, 1662: 41, 1681: 25, 2041: 21, 1060: 40, 663: 40, 1918: 38, 1618: 29, 1708: 52, 624: 46, 916: 48, 1240: 38, 1358: 31, 1818: 32, 718: 57, 1014: 46, 310: 41, 1901: 45, 1884: 39, 2036: 32, 1246: 54, 1487: 51, 1873: 43, 1633: 38, 1636: 29, 845: 41, 196: 47, 2010: 38, 1676: 37, 218: 26, 95: 44, 1415: 13, 291: 38, 64: 45, 1140: 55, 1159: 51, 258: 41, 281: 44, 1478: 45, 1482: 48, 961: 29, 1668: 52, 122: 36, 1070: 38, 1098: 37, 630: 61, 365: 40, 528: 28, 114: 51, 128: 40, 1498: 44, 759: 47, 1981: 40, 517: 42, 292: 35, 2023: 29, 812: 25, 295: 50, 723: 46, 1052: 34, 1445: 31, 1878: 46, 534: 28, 1391: 43, 15: 30, 1018: 57, 1042: 25, 1940: 49, 1938: 57, 350: 32, 1741: 21, 389: 23, 467: 44, 1207: 40, 477: 55, 939: 55, 1085: 24, 1109: 38, 2018: 42, 1277: 22, 986: 35, 2034: 31, 1808: 40, 1576: 49, 1213: 47, 1644: 53, 488: 47, 1227: 51, 786: 56, 1122: 32, 1982: 38, 973: 51, 1694: 41, 2037: 23, 1131: 48, 335: 35, 352: 33, 1520: 41, 849: 16, 340: 27, 1537: 33, 1588: 40, 168: 28, 1065: 32, 523: 39, 233: 54, 583: 43, 922: 54, 640: 36, 784: 55, 809: 20, 173: 37, 395: 38, 1356: 43, 1965: 35, 1158: 46, 1374: 49, 1271: 44, 1497: 40, 656: 31, 1283: 37, 306: 34, 1345: 48, 147: 37, 1055: 40, 581: 51, 1243: 51, 1457: 43, 1401: 20, 24: 48, 1909: 32, 371: 19, 220: 18, 666: 43, 57: 57, 1108: 48, 414: 44, 1804: 30, 1226: 53, 955: 44, 1870: 50, 1377: 45, 133: 48, 1353: 53, 960: 37, 2007: 35, 644: 31, 1797: 37, 1653: 29, 1691: 37, 289: 32, 543: 35, 1403: 31, 1210: 42, 1529: 30, 550: 26, 1793: 29, 893: 46, 1105: 45, 1813: 31, 1783: 28, 1834: 46, 802: 25, 0: 22, 502: 49, 749: 53, 469: 34, 2030: 25, 1111: 25, 1969: 30, 1814: 34, 347: 32, 1341: 44, 1976: 48, 1827: 44, 1637: 28, 1337: 49, 418: 45, 941: 46, 1466: 18, 1461: 46, 187: 48, 1815: 30, 308: 19, 1203: 52, 136: 49, 1206: 31, 152: 33, 8: 38, 1958: 51, 732: 46, 1590: 51, 213: 36, 1980: 37, 1369: 26, 1945: 50, 1320: 47, 243: 46, 1812: 30, 1816: 21, 1985: 49, 822: 42, 343: 25, 753: 49, 872: 54, 1526: 43, 1069: 36, 458: 49, 1047: 35, 1555: 38, 1212: 45, 416: 39, 873: 51, 1762: 44, 1911: 27, 37: 39, 1921: 27, 818: 37, 1680: 33, 813: 26, 1531: 15, 601: 49, 1456: 47, 1572: 42, 1465: 24, 1854: 45, 156: 20, 100: 29, 1844: 23, 1061: 31, 1922: 17, 1897: 50, 1532: 12, 1525: 46, 1717: 25, 617: 54, 1419: 37, 358: 51, 198: 43, 1119: 36, 1821: 40, 1839: 33, 1262: 46, 1852: 41, 974: 51, 1030: 48, 1888: 31, 1389: 43, 572: 53, 1137: 50, 694: 47, 1462: 29, 1955: 43, 71: 28, 1222: 49, 405: 41, 1795: 28, 2027: 38, 1920: 23, 791: 39, 124: 31, 149: 33, 827: 31, 278: 30, 1711: 28, 1232: 49, 541: 50, 222: 11, 1541: 35, 1249: 43, 740: 50, 530: 25, 866: 41, 1294: 37, 68: 39, 1788: 44, 2020: 27, 1281: 40, 1332: 14, 300: 47, 819: 47, 1348: 43, 1453: 23, 1282: 37, 1311: 51, 1929: 42, 66: 41, 370: 24, 1629: 13, 107: 30, 158: 38, 565: 42, 569: 7, 1308: 18, 913: 49, 1422: 45, 1966: 29, 862: 49, 170: 32, 682: 57, 699: 63, 1005: 22, 221: 16, 1157: 50, 586: 45, 1298: 41, 1511: 52, 888: 21, 120: 43, 1040: 28, 538: 40, 150: 37, 956: 49, 54: 25, 386: 33, 393: 24, 1471: 15, 249: 40, 280: 22, 75: 45, 5: 25, 1097: 23, 1379: 40, 1285: 24, 1307: 22, 2011: 32, 1642: 42, 246: 45, 1221: 47, 1627: 16, 806: 35, 612: 56, 1684: 20, 1101: 25, 1972: 52, 662: 39, 313: 29, 652: 28, 391: 33, 1469: 18, 899: 41, 1074: 34, 251: 29, 162: 43, 1523: 43, 1121: 41, 1898: 52, 1351: 41, 717: 52, 1334: 13, 859: 24, 2003: 26, 1426: 30, 62: 57, 1289: 41, 1803: 38, 1336: 47, 1470: 17, 1528: 46, 1791: 30, 203: 36, 432: 31, 1589: 52, 118: 38, 685: 50, 396: 45, 1448: 38, 1769: 33, 204: 46, 966: 32, 379: 36, 1408: 41, 1546: 26, 881: 45, 499: 48, 452: 36, 907: 56, 2: 26, 1660: 34, 1136: 51, 1291: 45, 582: 46, 1409: 26, 977: 38, 1774: 25, 1263: 46, 1890: 27, 1259: 49, 820: 42, 1641: 48, 1679: 34, 1593: 46, 1742: 17, 1413: 25, 1473: 22, 2002: 32, 116: 39, 1078: 25, 229: 24, 556: 39, 1452: 28, 1771: 28, 1840: 35, 836: 37, 385: 22, 1179: 56, 884: 42, 839: 36, 1651: 43, 1542: 33, 185: 55, 547: 36, 1624: 29, 88: 48, 18: 24, 1551: 21, 1017: 28, 559: 21, 537: 30, 1420: 36, 1734: 38, 1275: 34, 76: 33, 1760: 53, 1690: 31, 2039: 20, 658: 44, 1923: 52, 1650: 39, 2038: 19, 608: 51, 429: 26, 6: 23, 1359: 27, 342: 20, 1879: 47, 1399: 27, 810: 36, 1686: 16, 858: 27, 435: 27, 211: 20, 22: 35, 137: 39, 322: 12, 374: 34, 1043: 23, 794: 30, 554: 38, 1417: 10, 1883: 25, 1817: 17, 1333: 10, 1360: 19, 172: 36, 1051: 20, 1628: 12, 228: 20, 1455: 16}\n",
      "Clustering Coefficients: {266: 0.4941944847605225, 268: 0.5257142857142857, 400: 0.4992887624466572, 1022: 0.4781297134238311, 928: 0.43246753246753245, 1141: 0.43703703703703706, 298: 0.45063879210220675, 745: 0.4246068455134135, 1447: 0.6108374384236454, 1706: 0.4291979949874687, 490: 0.4710884353741497, 915: 0.5293466223698782, 1620: 0.5606060606060606, 1634: 0.562753036437247, 1257: 0.40691489361702127, 1582: 0.45410628019323673, 4: 0.5007112375533428, 1961: 0.5070921985815603, 1220: 0.4708603145235893, 1700: 0.5198067632850242, 1256: 0.38693877551020406, 1357: 0.5284552845528455, 129: 0.5924426450742241, 155: 0.7898550724637681, 561: 0.5391304347826087, 566: 0.6507936507936508, 1421: 0.5141700404858299, 1424: 0.5015015015015015, 44: 0.696969696969697, 47: 0.8297101449275363, 904: 0.4291101055806938, 905: 0.46680642907058, 1115: 0.5231707317073171, 1125: 0.5444444444444444, 1975: 0.5494912118408881, 1983: 0.5113122171945701, 619: 0.47429078014184395, 921: 0.4177683765203596, 273: 0.5856236786469344, 284: 0.5434343434343434, 1138: 0.4383116883116883, 1486: 0.4492481203007519, 1133: 0.5158562367864693, 1142: 0.5143385753931545, 1458: 0.6252873563218391, 1464: 0.541871921182266, 424: 0.5846372688477952, 453: 0.6231527093596059, 1229: 0.5020408163265306, 1604: 0.43376623376623374, 1671: 0.5344129554655871, 1757: 0.4634146341463415, 1344: 0.5110544217687075, 1362: 0.5585858585858586, 1476: 0.8939393939393939, 1481: 0.44727891156462585, 1687: 0.6500711237553343, 1701: 0.4985507246376812, 99: 0.6460317460317461, 104: 0.480083857442348, 442: 0.8441558441558441, 443: 0.8833333333333333, 1488: 0.4450354609929078, 1491: 0.5085034013605442, 254: 0.6086956521739131, 392: 0.4576923076923077, 419: 0.4528301886792453, 459: 0.5221088435374149, 1339: 0.46897163120567376, 1368: 0.677536231884058, 971: 0.6174242424242424, 972: 0.5592469545957918, 671: 0.5336879432624113, 680: 0.4811320754716981, 1183: 0.38310708898944196, 1794: 0.5757575757575758, 1375: 0.4831591173054588, 1964: 0.5426356589147286, 1543: 0.6310160427807486, 1548: 0.7204301075268817, 166: 0.7241379310344828, 171: 0.5984848484848485, 245: 0.4230769230769231, 464: 0.4628019323671498, 1026: 0.4881720430107527, 1029: 0.46881720430107526, 1886: 0.5516908212560386, 1887: 0.5616161616161616, 1977: 0.5120663650075414, 2005: 0.5525252525252525, 449: 0.5989304812834224, 614: 0.4549019607843137, 2024: 0.5561497326203209, 509: 0.4423558897243108, 510: 0.476078431372549, 593: 0.4616096207215541, 1147: 0.40753045404208194, 1328: 0.5467160037002775, 1367: 0.7207977207977208, 1352: 0.4107308048103608, 1953: 0.5303030303030303, 1309: 0.5690821256038647, 1317: 0.49129172714078373, 1231: 0.47737556561085975, 1434: 0.5540540540540541, 186: 0.4521044992743106, 234: 0.4680696661828737, 637: 0.4388539482879106, 695: 0.47099930118798045, 1863: 0.46040816326530615, 1876: 0.5625692137320044, 1321: 0.4671985815602837, 1327: 0.5391304347826087, 161: 0.4919191919191919, 177: 0.4513788098693759, 1081: 0.5087082728592163, 1086: 0.729064039408867, 1664: 0.5336879432624113, 1666: 0.4948051948051948, 504: 0.5008503401360545, 516: 0.5249169435215947, 564: 0.48287910552061497, 567: 0.670995670995671, 163: 0.56006006006006, 223: 0.6133004926108374, 1425: 0.5862068965517241, 1550: 0.6798941798941799, 1564: 0.6184615384615385, 1875: 0.551051051051051, 947: 0.43434343434343436, 2025: 0.5115384615384615, 584: 0.4346153846153846, 1973: 0.5568917668825162, 1033: 0.5777777777777777, 1045: 0.6516516516516516, 1093: 0.5126436781609195, 1096: 0.6666666666666666, 1194: 0.42272727272727273, 1902: 0.4108527131782946, 1151: 0.4525974025974026, 1266: 0.4693446088794926, 34: 0.5149359886201992, 752: 0.44863731656184486, 526: 0.6646153846153846, 600: 0.4666666666666667, 1163: 0.46806039488966317, 643: 0.48412698412698413, 1799: 0.5793103448275863, 216: 0.5064102564102564, 276: 0.6073968705547653, 285: 0.581081081081081, 667: 0.4915433403805497, 1527: 0.6470588235294118, 1553: 0.5135135135135135, 575: 0.44816326530612244, 1106: 0.5232323232323233, 1719: 0.6079545454545454, 1723: 0.7047619047619048, 1088: 0.5004081632653061, 1102: 0.7962962962962963, 1948: 0.4976873265494912, 1960: 0.5180388529139686, 511: 0.49577167019027485, 532: 0.58994708994709, 1731: 0.6774193548387096, 1733: 0.7355072463768116, 631: 0.4701298701298701, 634: 0.4396681749622926, 1492: 0.4751921733053808, 1587: 0.4251207729468599, 1954: 0.4228723404255319, 479: 0.4292207792207792, 994: 0.4856743535988819, 1970: 0.4796380090497738, 399: 0.5210084033613446, 476: 0.44268476621417796, 1925: 0.5178571428571429, 1949: 0.42138364779874216, 397: 0.49829931972789115, 403: 0.49825783972125437, 1383: 0.488388969521045, 1400: 0.7698412698412699, 1443: 0.5587301587301587, 1451: 0.5051282051282051, 283: 0.5478260869565217, 301: 0.47658979734451434, 926: 0.46879535558780844, 932: 0.4200680272108844, 1805: 0.5462184873949579, 2032: 0.485024154589372, 1786: 0.525609756097561, 1790: 0.4843205574912892, 1937: 0.5098039215686274, 1959: 0.4005805515239477, 409: 0.719047619047619, 413: 0.5284552845528455, 92: 0.4073469387755102, 706: 0.5551684088269454, 235: 0.4640111809923131, 260: 0.5391304347826087, 427: 0.6674876847290641, 430: 0.5682926829268292, 1182: 0.42697414395527605, 2026: 0.5411605937921727, 1287: 0.4883720930232558, 1288: 0.5748987854251012, 605: 0.49387755102040815, 702: 0.4573934837092732, 388: 0.589247311827957, 475: 0.4745605920444033, 1649: 0.6116642958748222, 1677: 0.4831372549019608, 1267: 0.4505050505050505, 1575: 0.43537414965986393, 978: 0.4634920634920635, 1472: 0.7426470588235294, 121: 0.6073170731707317, 131: 0.6307692307692307, 938: 0.445578231292517, 981: 0.49822695035460995, 989: 0.44862155388471175, 577: 0.45475113122171945, 1128: 0.4230769230769231, 1841: 0.4796747967479675, 1847: 0.6169354838709677, 1781: 0.49098039215686273, 1796: 0.517948717948718, 404: 0.5414634146341464, 470: 0.5564516129032258, 307: 0.5527065527065527, 486: 0.4376321353065539, 482: 0.51010101010101, 487: 0.3987049028677151, 1270: 0.4196078431372549, 2031: 0.47593582887700536, 1493: 0.5346901017576319, 1514: 0.47868623340321453, 56: 0.5016835016835017, 86: 0.49612403100775193, 176: 0.4517345399698341, 188: 0.4302721088435374, 2042: 0.7309941520467836, 613: 0.4494857834240774, 943: 0.4514124293785311, 360: 0.4375907111756168, 497: 0.41228070175438597, 1896: 0.5007256894049347, 1904: 0.5102040816326531, 826: 0.5384615384615384, 1990: 0.5110336817653891, 1619: 0.7137681159420289, 1626: 0.7279411764705882, 1505: 0.5231707317073171, 1524: 0.5082956259426847, 677: 0.44033302497687327, 1867: 0.4251207729468599, 1623: 0.5503875968992248, 1745: 0.45213137665967856, 1848: 0.5269230769230769, 1350: 0.4174972314507198, 1586: 0.4355179704016913, 603: 0.40619520748100524, 821: 0.6189516129032258, 1996: 0.45182724252491696, 1635: 0.5614973262032086, 1755: 0.4888888888888889, 1674: 0.49254901960784314, 1683: 0.8142292490118577, 1390: 0.42857142857142855, 1924: 0.5027450980392156, 1500: 0.47394957983193275, 1530: 0.5128205128205128, 832: 0.6928104575163399, 842: 0.5076923076923077, 32: 0.5920634920634921, 35: 0.5180023228803716, 2017: 0.4457912457912458, 2022: 0.7353846153846154, 983: 0.515263644773358, 1011: 0.46901960784313723, 315: 0.5313131313131313, 323: 0.5204081632653061, 2029: 0.48484848484848486, 995: 0.48491704374057315, 1021: 0.5119047619047619, 869: 0.5261324041811847, 882: 0.45725490196078433, 948: 0.4674509803921569, 1175: 0.4946808510638298, 1915: 0.4924585218702866, 1930: 0.402020202020202, 327: 0.45500725689404936, 333: 0.6344238975817923, 1187: 0.48138297872340424, 1191: 0.42452830188679247, 1756: 0.4441489361702128, 1398: 0.7247311827956989, 1411: 0.6666666666666666, 670: 0.5221631205673759, 672: 0.49019607843137253, 1016: 0.5462184873949579, 1153: 0.5, 1580: 0.5221987315010571, 841: 0.44387755102040816, 1171: 0.4563265306122449, 1597: 0.55049786628734, 1892: 0.4513006654567453, 1919: 0.5714285714285714, 462: 0.4698581560283688, 908: 0.47058823529411764, 382: 0.526829268292683, 390: 0.5640394088669951, 1242: 0.46820405310971347, 1248: 0.47294117647058825, 725: 0.4906122448979592, 729: 0.4744897959183674, 876: 0.4189189189189189, 898: 0.45365853658536587, 1392: 0.43333333333333335, 1946: 0.47435897435897434, 1807: 0.558974358974359, 208: 0.5226890756302521, 210: 0.6182336182336182, 719: 0.5319148936170213, 914: 0.44830917874396137, 1254: 0.48103607770582796, 1258: 0.3961352657004831, 739: 0.4064625850340136, 1850: 0.6666666666666666, 2043: 0.8166666666666667, 737: 0.4109014675052411, 363: 0.4431082331174838, 498: 0.4698340874811463, 437: 0.8, 447: 0.5304347826086957, 857: 0.47804878048780486, 160: 0.5487804878048781, 169: 0.8315789473684211, 1020: 0.502177068214804, 1027: 0.49376114081996436, 1880: 0.5590327169274538, 1885: 0.547568710359408, 1247: 0.5249169435215947, 988: 0.46331236897274636, 1489: 0.3998790078644888, 587: 0.467687074829932, 1145: 0.5178571428571429, 263: 0.5404040404040404, 267: 0.4833091436865022, 1: 0.5977011494252874, 1987: 0.5115248226950354, 792: 0.6988505747126437, 796: 0.7016129032258065, 1193: 0.4596078431372549, 1894: 0.5, 1652: 0.6873563218390805, 1654: 0.6647727272727273, 1234: 0.45507246376811594, 1895: 0.4107683000604961, 181: 0.4844804318488529, 642: 0.5070921985815603, 599: 0.4725177304964539, 1155: 0.4241854636591479, 1743: 0.4662349676225717, 1772: 0.6030769230769231, 1592: 0.4695210449927431, 1603: 0.45791245791245794, 215: 0.5169133192389006, 226: 0.6149732620320856, 275: 0.5813953488372093, 277: 0.6705882352941176, 1075: 0.6722689075630253, 1084: 0.6903225806451613, 426: 0.6992753623188406, 446: 0.5609756097560976, 598: 0.4539969834087481, 930: 0.42612244897959184, 755: 0.49709639953542395, 1354: 0.5012244897959184, 1438: 0.39183673469387753, 199: 0.46923076923076923, 632: 0.46980392156862744, 1087: 0.5052410901467506, 1094: 0.5320197044334976, 1947: 0.47285067873303166, 1952: 0.5143385753931545, 1188: 0.49577167019027485, 1900: 0.475177304964539, 1710: 0.6553030303030303, 138: 0.4357076780758557, 164: 0.5156794425087108, 570: 0.5026595744680851, 998: 0.5656565656565656, 1430: 0.5645161290322581, 1433: 0.5115384615384615, 1190: 0.4192176870748299, 1192: 0.3940795559666975, 1984: 0.5, 1992: 0.5049786628733998, 282: 0.5760743321718932, 293: 0.5565656565656566, 359: 0.4489795918367347, 513: 0.4396681749622926, 1224: 0.5411605937921727, 1715: 0.5862068965517241, 190: 0.42109929078014185, 704: 0.45614035087719296, 625: 0.46530612244897956, 1485: 0.47938504542278126, 1490: 0.41885521885521887, 1237: 0.4634146341463415, 1388: 0.45063879210220675, 1696: 0.6546546546546547, 968: 0.678030303030303, 1126: 0.4948717948717949, 1557: 0.4308510638297872, 1828: 0.4073446327683616, 1829: 0.45387205387205387, 2014: 0.49404761904761907, 2019: 0.6042780748663101, 1673: 0.4751607247223846, 1726: 0.5641025641025641, 126: 0.6207317073170732, 130: 0.6822660098522167, 1197: 0.4521044992743106, 1208: 0.5284552845528455, 689: 0.4886274509803922, 1251: 0.4889663182346109, 1444: 0.5563025210084034, 242: 0.4894291754756871, 463: 0.4753623188405797, 1023: 0.47463002114164904, 1028: 0.46345811051693403, 1176: 0.4419306184012066, 140: 0.4716981132075472, 1000: 0.5301960784313725, 1044: 0.7445887445887446, 1506: 0.5613107822410148, 332: 0.5687103594080338, 356: 0.5305832147937412, 1556: 0.42995169082125606, 1552: 0.5777777777777777, 975: 0.5319148936170213, 987: 0.626984126984127, 1035: 0.38414634146341464, 1038: 0.7025210084033613, 1835: 0.5132978723404256, 1845: 0.4957983193277311, 1573: 0.4484848484848485, 735: 0.5485661424606846, 746: 0.3996299722479186, 1265: 0.48414376321353064, 193: 0.4584206848357792, 197: 0.4450354609929078, 518: 0.5106685633001422, 519: 0.5072463768115942, 602: 0.4021857923497268, 1156: 0.4246823956442831, 1204: 0.5817073170731707, 1622: 0.562753036437247, 1737: 0.48717948717948717, 1355: 0.5591966173361522, 1393: 0.5647840531561462, 1855: 0.46304675716440424, 687: 0.5493197278911565, 705: 0.5265306122448979, 272: 0.43537414965986393, 1474: 0.6096866096866097, 230: 0.47439613526570046, 237: 0.5328014184397163, 1950: 0.5198889916743756, 525: 0.6707692307692308, 766: 0.5110204081632653, 421: 0.461734693877551, 936: 0.45475113122171945, 591: 0.40185830429732866, 1429: 0.6083743842364532, 1692: 0.5494949494949495, 314: 0.5974358974358974, 742: 0.5087082728592163, 762: 0.43636363636363634, 1962: 0.5584541062801932, 1963: 0.5697674418604651, 535: 0.5508021390374331, 1385: 0.5449275362318841, 1728: 0.7166666666666667, 1732: 0.6609848484848485, 1196: 0.48299319727891155, 1871: 0.5053061224489795, 26: 0.40691489361702127, 33: 0.5954022988505747, 369: 0.5952380952380952, 372: 0.5418894830659536, 665: 0.4799154334038055, 1440: 0.5615615615615616, 1450: 0.5207317073170732, 731: 0.5101449275362319, 761: 0.44, 63: 0.5391156462585034, 73: 0.6085365853658536, 923: 0.449874686716792, 931: 0.4708603145235893, 381: 0.5405405405405406, 1820: 0.5634146341463414, 1856: 0.4660633484162896, 232: 0.45981830887491265, 259: 0.5378048780487805, 1092: 0.4466571834992888, 1117: 0.44148936170212766, 1152: 0.499113475177305, 1168: 0.4485049833887043, 692: 0.44979591836734695, 1225: 0.42891712038717483, 1646: 0.39223057644110276, 1211: 0.5306553911205074, 1748: 0.4653198653198653, 953: 0.6666666666666666, 958: 0.49615384615384617, 1278: 0.8235294117647058, 1280: 0.4864864864864865, 175: 0.4812925170068027, 664: 0.48731501057082455, 1522: 0.401219512195122, 436: 0.7569230769230769, 439: 0.9411764705882353, 1296: 0.6880570409982175, 1297: 0.6429587482219061, 1507: 0.5087881591119334, 1517: 0.47215686274509805, 727: 0.4276729559748428, 94: 0.4115942028985507, 675: 0.44979591836734695, 1342: 0.5221088435374149, 990: 0.46936026936026937, 1602: 0.48491704374057315, 1754: 0.4318181818181818, 1239: 0.4496124031007752, 1702: 0.4653098982423682, 148: 0.7660098522167488, 157: 0.8354978354978355, 1579: 0.4506531204644412, 244: 0.43617021276595747, 1216: 0.47729789590254706, 1718: 0.6008064516129032, 431: 0.6117424242424242, 445: 0.6185383244206774, 1214: 0.42835595776772245, 1645: 0.4255892255892256, 491: 0.5121951219512195, 496: 0.4426705370101596, 716: 0.48491704374057315, 834: 1.0, 835: 1.0, 125: 0.6268292682926829, 146: 0.6722689075630253, 985: 0.6088709677419355, 1004: 0.6182266009852216, 684: 0.4479385045422781, 1830: 0.47379454926624737, 506: 0.5590327169274538, 85: 0.4573643410852713, 747: 0.4048309178743961, 1346: 0.4811594202898551, 143: 0.6346153846153846, 1363: 0.6072874493927125, 1364: 0.5644599303135889, 1343: 0.47843137254901963, 1533: 0.6205128205128205, 853: 0.4417508417508417, 2016: 0.4404040404040404, 1178: 0.43658679135008766, 1584: 0.43537414965986393, 925: 0.4746008708272859, 546: 0.6470588235294118, 553: 0.6471471471471472, 269: 0.5545454545454546, 697: 0.4922558922558923, 722: 0.4513788098693759, 1129: 0.4676328502415459, 1199: 0.45551378446115287, 1872: 0.48491704374057315, 29: 0.5675675675675675, 1509: 0.5736434108527132, 1539: 0.7681159420289855, 1143: 0.476078431372549, 851: 0.49292929292929294, 41: 0.41352657004830917, 901: 0.42293233082706766, 902: 0.45981830887491265, 1376: 0.534453781512605, 744: 0.45500725689404936, 918: 0.42775510204081635, 324: 0.508235294117647, 552: 0.81, 1395: 0.6875, 1410: 0.6470588235294118, 1185: 0.48244897959183675, 1600: 0.4833091436865022, 861: 0.46431372549019606, 326: 0.5283687943262412, 378: 0.432156862745098, 1713: 0.5315315315315315, 1200: 0.5012244897959184, 36: 0.5397435897435897, 50: 0.54421768707483, 96: 0.5666666666666667, 101: 0.6676923076923077, 247: 0.5004081632653061, 270: 0.4669387755102041, 679: 0.5050798258345428, 681: 0.4967532467532468, 440: 0.8043478260869565, 1750: 0.45925925925925926, 1759: 0.4528301886792453, 1180: 0.4707070707070707, 1606: 0.4249158249158249, 999: 0.5145098039215686, 1036: 0.47735191637630664, 589: 0.42857142857142855, 1059: 0.487987987987988, 331: 0.5143288084464555, 348: 0.47780126849894294, 542: 0.6005398110661269, 568: 0.8241758241758241, 760: 0.5414141414141415, 674: 0.5336879432624113, 734: 0.5180388529139686, 738: 0.40041928721174, 42: 0.5299145299145299, 1908: 0.5326688815060908, 1594: 0.4978858350951374, 1596: 0.5076923076923077, 183: 0.45981830887491265, 635: 0.5205128205128206, 563: 0.4701298701298701, 856: 0.47851335656213706, 217: 0.6045977011494252, 219: 0.6666666666666666, 771: 0.5145098039215686, 805: 0.5080213903743316, 53: 0.6752688172043011, 754: 0.46956521739130436, 903: 0.48784313725490197, 924: 0.48868778280542985, 1782: 0.517113783533765, 1832: 0.48299319727891155, 194: 0.44920174165457183, 236: 0.5429951690821256, 456: 0.4914965986394558, 1306: 0.7592592592592593, 1314: 0.45348837209302323, 789: 0.5066666666666667, 795: 0.6857142857142857, 1245: 0.4629898403483309, 178: 0.5181818181818182, 641: 0.5874822190611664, 940: 0.5137254901960784, 964: 0.5915966386554622, 98: 0.5825027685492802, 123: 0.5548780487804879, 1318: 0.4987755102040816, 1324: 0.5401069518716578, 657: 0.5543672014260249, 10: 0.5132575757575758, 693: 0.4726530612244898, 2028: 0.4885290148448043, 801: 0.7351778656126482, 1661: 0.5791805094130675, 1663: 0.7661538461538462, 501: 0.4752941176470588, 1801: 0.6064516129032258, 224: 0.5946969696969697, 286: 0.5187165775401069, 1512: 0.46530612244897956, 1540: 0.7578947368421053, 1295: 0.7102272727272727, 1313: 0.503030303030303, 192: 0.4155354449472097, 302: 0.5060331825037707, 303: 0.5636363636363636, 1640: 0.45194805194805193, 1725: 0.5600539811066126, 1519: 0.47534013605442177, 736: 0.5068027210884354, 1956: 0.483843537414966, 811: 0.7301587301587301, 1656: 0.6739495798319328, 1669: 0.4919191919191919, 1716: 0.6534391534391535, 1720: 0.5769230769230769, 1170: 0.48282828282828283, 980: 0.48777078965758214, 1007: 0.5175510204081633, 1031: 0.5207729468599034, 1439: 0.5292929292929293, 1442: 0.5140096618357488, 1139: 0.44377104377104376, 1150: 0.4470659407138536, 1201: 0.43600233781414377, 996: 0.46003016591251883, 1290: 0.5585858585858586, 1319: 0.5363475177304965, 80: 0.5393154486586494, 82: 0.4898989898989899, 1253: 0.4557823129251701, 1437: 0.46167557932263814, 1160: 0.42828282828282827, 1002: 0.5598141695702671, 1037: 0.6435897435897436, 1494: 0.5274822695035462, 1499: 0.5619047619047619, 334: 0.6647727272727273, 349: 0.6470588235294118, 1034: 0.46099290780141844, 1837: 0.6436781609195402, 1838: 0.6048387096774194, 863: 0.5348837209302325, 878: 0.4016393442622951, 1685: 0.8263157894736842, 135: 0.5015082956259427, 139: 0.43902439024390244, 997: 0.44234800838574423, 945: 0.5890243902439024, 1934: 0.49379432624113473, 346: 0.6420454545454546, 1146: 0.47246376811594204, 1166: 0.43868921775898523, 46: 0.7291666666666666, 67: 0.5889046941678521, 1340: 0.48625792811839325, 1971: 0.4435064935064935, 1386: 0.44720965309200605, 686: 0.44107744107744107, 1181: 0.4155464640561075, 698: 0.47868623340321453, 1549: 0.7435897435897436, 816: 0.5101214574898786, 707: 0.5060331825037707, 715: 0.475974025974026, 330: 0.3787755102040816, 765: 0.475867269984917, 1032: 0.6219512195121951, 58: 0.5158371040723982, 77: 0.5689176688251619, 574: 0.44148936170212766, 1009: 0.4961038961038961, 1053: 0.5681511470985156, 1501: 0.5974358974358974, 1515: 0.48484848484848486, 1217: 0.4430976430976431, 1561: 0.502903600464576, 1566: 0.4831591173054588, 1223: 0.4850498338870432, 1261: 0.4432624113475177, 1274: 0.7, 894: 0.452431289640592, 1905: 0.4879336349924585, 1255: 0.5203252032520326, 1459: 0.6164021164021164, 202: 0.47950089126559714, 206: 0.45454545454545453, 1062: 0.6666666666666666, 1064: 0.5913621262458472, 1273: 0.6236559139784946, 1284: 0.49411764705882355, 1695: 0.6137566137566137, 39: 0.5793103448275863, 696: 0.4843358395989975, 714: 0.45587375803623614, 823: 0.5585585585585585, 1616: 0.48846153846153845, 828: 0.6150537634408603, 833: 0.8727272727272727, 179: 0.4725158562367865, 195: 0.47363552266419984, 1039: 0.692436974789916, 65: 0.580338266384778, 93: 0.3867595818815331, 212: 0.5846702317290553, 257: 0.5856236786469344, 927: 0.4746008708272859, 540: 0.5791805094130675, 551: 0.861904761904762, 751: 0.5381205673758865, 481: 0.4686868686868687, 910: 0.4753623188405797, 23: 0.5048780487804878, 580: 0.5048780487804878, 889: 0.4596078431372549, 1394: 0.6742424242424242, 1402: 0.7007575757575758, 1639: 0.48627450980392156, 895: 0.437862950058072, 900: 0.4411764705882353, 1758: 0.4682926829268293, 655: 0.6058201058201058, 659: 0.4573643410852713, 1120: 0.3971631205673759, 1906: 0.5679925994449584, 1927: 0.46938775510204084, 1238: 0.4365750528541226, 1449: 0.5476529160739687, 607: 0.4149620105201636, 618: 0.46980392156862744, 25: 0.41966173361522197, 362: 0.4592198581560284, 787: 0.4379432624113475, 30: 0.5988620199146515, 48: 0.6097560975609756, 1678: 0.6121951219512195, 90: 0.5119047619047619, 950: 0.467687074829932, 957: 0.461734693877551, 1161: 0.4396681749622926, 1177: 0.46464646464646464, 433: 0.6633064516129032, 438: 0.8571428571428571, 1479: 0.5256038647342995, 410: 0.6789473684210526, 454: 0.6239316239316239, 1504: 0.6793650793650794, 1516: 0.5516908212560386, 929: 0.46304675716440424, 1019: 0.48754208754208755, 962: 0.7310344827586207, 967: 0.5073891625615764, 1822: 0.717948717948718, 1825: 0.46907993966817496, 299: 0.4323467230443975, 623: 0.4183535762483131, 448: 0.5378787878787878, 1236: 0.4820295983086681, 1305: 0.5795586527293844, 911: 0.4574468085106383, 296: 0.5505050505050505, 325: 0.5173453996983409, 1460: 0.47246376811594204, 1611: 0.5153846153846153, 1763: 0.4539969834087481, 97: 0.5757575757575758, 115: 0.494949494949495, 489: 0.4884366327474561, 1877: 0.5068027210884354, 1882: 0.5579831932773109, 500: 0.4200603318250377, 505: 0.5010570824524313, 783: 0.49098039215686273, 793: 0.49082125603864735, 843: 0.5705705705705706, 844: 0.5946969696969697, 521: 0.5145180023228804, 628: 0.4620408163265306, 690: 0.47278911564625853, 134: 0.4968553459119497, 1889: 0.7035573122529645, 669: 0.5301418439716312, 691: 0.44392156862745097, 1378: 0.5443548387096774, 1942: 0.49393939393939396, 3: 0.9487179487179487, 1312: 0.5177304964539007, 1322: 0.45897435897435895, 803: 0.6005291005291006, 1655: 0.6420168067226891, 555: 0.574390243902439, 562: 0.5143385753931545, 713: 0.4954577218728162, 1866: 0.5025641025641026, 1881: 0.6160919540229886, 1538: 0.81, 1998: 0.6529160739687055, 2000: 0.696969696969697, 38: 0.6194331983805668, 43: 0.6739495798319328, 512: 0.5307692307692308, 865: 0.47780126849894294, 1446: 0.5827956989247312, 1672: 0.5541871921182266, 1427: 0.5425101214574899, 1599: 0.5378151260504201, 341: 0.8153846153846154, 1613: 0.4583333333333333, 1785: 0.4830917874396135, 1722: 0.6114942528735632, 1205: 0.604551920341394, 1209: 0.483265306122449, 455: 0.6256684491978609, 45: 0.6711711711711712, 59: 0.5514184397163121, 105: 0.5981416957026713, 110: 0.7473684210526316, 917: 0.4298642533936652, 1107: 0.5232558139534884, 965: 0.5868945868945868, 1826: 0.48214285714285715, 1380: 0.5549242424242424, 1916: 0.4736394557823129, 1944: 0.53003003003003, 398: 0.4992887624466572, 1857: 0.46122448979591835, 351: 0.5841269841269842, 573: 0.5211416490486258, 1008: 0.5204081632653061, 1260: 0.445578231292517, 743: 0.5363475177304965, 1605: 0.4991496598639456, 764: 0.504313725490196, 522: 0.5220483641536273, 112: 0.5365402405180388, 590: 0.42318840579710143, 984: 0.5249709639953543, 465: 0.45555555555555555, 1293: 0.6149193548387096, 1272: 0.5507936507936508, 460: 0.4622926093514329, 1006: 0.7142857142857143, 750: 0.5158371040723982, 763: 0.4186046511627907, 1978: 0.49795918367346936, 450: 0.5294871794871795, 471: 0.6061538461538462, 1670: 0.5333333333333333, 944: 0.5066666666666667, 979: 0.49743589743589745, 311: 0.6192307692307693, 312: 0.6714285714285714, 1382: 0.49098039215686273, 594: 0.4447278911564626, 711: 0.4528301886792453, 650: 0.5738916256157636, 871: 0.46956521739130436, 1665: 0.47368421052631576, 1729: 0.5806451612903226, 492: 0.44715447154471544, 2008: 0.5564102564102564, 673: 0.4805194805194805, 366: 0.6003787878787878, 89: 0.5240816326530612, 91: 0.46187943262411346, 860: 0.4396103896103896, 877: 0.41097560975609754, 576: 0.4444444444444444, 1118: 0.4485049833887043, 189: 0.4200680272108844, 1735: 0.5232558139534884, 13: 0.6183908045977011, 610: 0.48653061224489796, 1503: 0.6048780487804878, 1508: 0.5666666666666667, 515: 0.4423076923076923, 1329: 0.5858250276854928, 661: 0.46431372549019606, 1144: 0.4751921733053808, 730: 0.5087881591119334, 1935: 0.444947209653092, 1558: 0.413472706155633, 1565: 0.5839080459770115, 1384: 0.504524886877828, 1412: 0.6413793103448275, 724: 0.4377104377104377, 1843: 0.5419354838709678, 1218: 0.50177304964539, 1874: 0.5487179487179488, 1787: 0.6169354838709677, 1802: 0.6477832512315271, 205: 0.481981981981982, 1063: 0.6167341430499326, 520: 0.5294117647058824, 785: 0.5097517730496454, 544: 0.7045454545454546, 728: 0.5246376811594203, 1913: 0.48707197763801535, 1914: 0.4688445251058681, 1571: 0.41877551020408166, 483: 0.5272727272727272, 151: 0.7720430107526882, 1071: 0.6441441441441441, 1073: 0.8416666666666667, 781: 0.42627533193570927, 1162: 0.4616096207215541, 1484: 0.4815686274509804, 1361: 0.8636363636363636, 503: 0.4897959183673469, 1169: 0.4579591836734694, 1581: 0.4426705370101596, 1625: 0.6476190476190476, 1632: 0.6042780748663101, 1186: 0.4502262443438914, 790: 0.513413506012951, 31: 0.5613107822410148, 1910: 0.47692307692307695, 748: 0.5059399021663172, 770: 0.4847605224963715, 1066: 0.7717391304347826, 1079: 0.5806763285024155, 1130: 0.44727891156462585, 1986: 0.583610188261351, 1988: 0.525609756097561, 1591: 0.46879535558780844, 384: 0.6920289855072463, 493: 0.40505050505050505, 549: 0.6059743954480796, 560: 0.9298245614035088, 676: 0.44242424242424244, 1833: 0.5207317073170732, 609: 0.4551948051948052, 611: 0.44805194805194803, 1951: 0.4669387755102041, 361: 0.4223512336719884, 780: 0.5051020408163265, 627: 0.475177304964539, 778: 0.5127551020408163, 797: 0.728735632183908, 1428: 0.5145180023228804, 622: 0.42917547568710357, 51: 0.5460992907801419, 909: 0.4727104532839963, 1764: 0.4563265306122449, 1767: 0.532051282051282, 807: 0.7315270935960592, 668: 0.48315602836879434, 1766: 0.39918176504967856, 1235: 0.40980573543015725, 1423: 0.4353535353535353, 1252: 0.47874149659863946, 288: 0.4413472706155633, 87: 0.5425531914893617, 1468: 0.6691176470588235, 616: 0.46191474493361284, 678: 0.38838612368024134, 108: 0.6920289855072463, 1778: 0.6060606060606061, 1823: 0.698005698005698, 1819: 0.6688172043010753, 1824: 0.5359911406423035, 1302: 0.7025210084033613, 294: 0.509713228492137, 402: 0.509469696969697, 1048: 0.625615763546798, 1279: 0.5523809523809524, 1315: 0.4107308048103608, 154: 0.7358870967741935, 165: 0.6338461538461538, 653: 0.610752688172043, 1798: 0.5445378151260504, 920: 0.449874686716792, 1968: 0.5905797101449275, 1891: 0.506938775510204, 726: 0.46879535558780844, 741: 0.49547511312217196, 2009: 0.4705128205128205, 514: 0.47357293868921774, 527: 0.6996047430830039, 531: 0.7134502923976608, 852: 0.4661224489795918, 238: 0.45625942684766213, 1123: 0.5806451612903226, 1316: 0.42730496453900707, 12: 0.64, 1202: 0.43546365914786966, 1609: 0.46897163120567376, 1090: 0.5576923076923077, 571: 0.48554421768707484, 227: 0.7445887445887446, 1547: 0.5226480836236934, 1286: 0.45883940620782726, 1495: 0.42828282828282827, 1049: 0.6201680672268908, 1768: 0.5871212121212122, 733: 0.5484848484848485, 757: 0.5522664199814986, 1893: 0.4699248120300752, 1907: 0.5824524312896406, 756: 0.4704016913319239, 824: 0.4489795918367347, 875: 0.4128205128205128, 69: 0.4817204301075269, 1643: 0.4198668714797747, 1167: 0.47502903600464574, 1095: 0.5833333333333334, 648: 0.6451612903225806, 649: 0.6209677419354839, 890: 0.45254901960784316, 1727: 0.6190476190476191, 79: 0.5065312046444121, 1865: 0.40333024976873266, 495: 0.41932367149758454, 592: 0.3961352657004831, 885: 0.5549242424242424, 539: 0.6173541963015647, 864: 0.47020408163265304, 367: 0.5735735735735735, 1638: 0.6995073891625616, 1738: 0.5256410256410257, 1371: 0.47836734693877553, 1496: 0.5, 703: 0.5098039215686274, 422: 0.43962585034013607, 854: 0.4716312056737589, 1116: 0.5253968253968254, 1974: 0.40670859538784065, 407: 0.5795454545454546, 1404: 0.6647727272727273, 1083: 0.5934959349593496, 1112: 0.7543859649122807, 415: 0.5412262156448203, 1574: 0.38461538461538464, 683: 0.41883116883116883, 1502: 0.5434343434343434, 1932: 0.5246376811594203, 49: 0.5568917668825162, 74: 0.5559666975023126, 710: 0.554006968641115, 1928: 0.4473429951690821, 434: 0.49099099099099097, 1292: 0.5536585365853659, 1612: 0.46511627906976744, 1614: 0.5161616161616162, 1765: 0.4642857142857143, 773: 0.5507399577167019, 1630: 0.7090909090909091, 1631: 0.6666666666666666, 61: 0.4143763213530655, 84: 0.45647058823529413, 942: 0.47309573724668064, 993: 0.4336329984135378, 891: 0.47020408163265304, 1851: 0.7359307359307359, 253: 0.5982905982905983, 701: 0.43682983682983684, 1800: 0.6129032258064516, 423: 0.5841269841269842, 474: 0.42525399129172714, 290: 0.43521594684385384, 321: 0.6789473684210526, 1518: 0.5010570824524313, 825: 0.48787878787878786, 830: 0.5806451612903226, 976: 0.4821256038647343, 1703: 0.47591836734693876, 1338: 0.4923469387755102, 837: 0.5095137420718816, 840: 0.4708603145235893, 1749: 0.4500907441016334, 1697: 0.615931721194879, 1698: 0.6352941176470588, 191: 0.42828282828282827, 320: 0.5423280423280423, 55: 0.6733333333333333, 804: 0.5763440860215053, 20: 0.5371120107962213, 1831: 0.44326530612244897, 1056: 0.5005537098560354, 1463: 0.5292307692307693, 1467: 0.6842105263157895, 814: 0.7368421052631579, 829: 0.5632798573975044, 1164: 0.4439746300211416, 1585: 0.43023255813953487, 758: 0.48214285714285715, 897: 0.41097560975609754, 1704: 0.4528301886792453, 912: 0.4717171717171717, 1475: 0.5720430107526882, 1477: 0.5681818181818182, 375: 0.6266666666666667, 1326: 0.5545454545454546, 255: 0.587737843551797, 886: 0.5866666666666667, 1693: 0.5761024182076814, 585: 0.46565656565656566, 1127: 0.46511627906976744, 1195: 0.45573294629898403, 265: 0.4423529411764706, 1534: 0.7040998217468806, 788: 0.43351063829787234, 946: 0.4599326599326599, 1483: 0.477891156462585, 153: 0.7866666666666666, 1013: 0.5678160919540229, 1015: 0.62, 774: 0.4767676767676768, 394: 0.5076923076923077, 368: 0.5487179487179488, 480: 0.4321266968325792, 1811: 0.6229838709677419, 214: 0.5828877005347594, 1068: 0.6854838709677419, 1072: 0.74, 1601: 0.4796380090497738, 239: 0.4447278911564626, 466: 0.48717948717948717, 620: 0.492600422832981, 1080: 0.5808080808080808, 1082: 0.5314009661835749, 720: 0.5274822695035462, 1149: 0.4274640088593577, 271: 0.3829787234042553, 1903: 0.3879492600422833, 106: 0.5252525252525253, 287: 0.5476190476190477, 1991: 0.6114942528735632, 606: 0.4283717679944095, 1709: 0.45714285714285713, 800: 0.7264957264957265, 1607: 0.4923469387755102, 1658: 0.7789473684210526, 1135: 0.4517345399698341, 1418: 0.553306342780027, 318: 0.524390243902439, 328: 0.40816326530612246, 769: 0.5204081632653061, 2012: 0.5314009661835749, 636: 0.4904862579281184, 28: 0.5333333333333333, 78: 0.5176470588235295, 117: 0.3878787878787879, 1165: 0.5036585365853659, 478: 0.4804421768707483, 1773: 0.6123188405797102, 1776: 0.7619047619047619, 626: 0.45073375262054505, 472: 0.4611764705882353, 1659: 0.7318548387096774, 1535: 0.7258064516129032, 174: 0.49797979797979797, 344: 0.6903225806451613, 604: 0.4572390572390572, 337: 0.5303643724696356, 354: 0.4840816326530612, 1372: 0.5254394079555966, 1967: 0.492176386913229, 231: 0.4318181818181818, 1480: 0.562137049941928, 963: 0.7628458498023716, 1366: 0.6141141141141141, 1751: 0.48340874811463047, 991: 0.4713804713804714, 1849: 0.539039039039039, 1577: 0.45790934320074006, 1595: 0.45408163265306123, 1608: 0.4939870490286771, 201: 0.589247311827957, 1746: 0.4801110083256244, 1777: 0.5015384615384615, 1381: 0.6276923076923077, 536: 0.5555555555555556, 1397: 0.7549857549857549, 1396: 0.716931216931217, 19: 0.6502463054187192, 21: 0.5121951219512195, 776: 0.4594594594594595, 1099: 0.6875, 1957: 0.4988235294117647, 1510: 0.4579710144927536, 529: 0.5439024390243903, 1373: 0.5592469545957918, 1387: 0.4575757575757576, 1617: 0.5634408602150538, 1747: 0.501219512195122, 1276: 0.7619047619047619, 1454: 0.5591397849462365, 319: 0.4948717948717949, 401: 0.4706533776301218, 473: 0.4454901960784314, 14: 0.5793226381461676, 27: 0.3820921985815603, 934: 0.41948051948051945, 935: 0.44047619047619047, 225: 0.5761904761904761, 1025: 0.4817073170731707, 1054: 0.5523809523809524, 1567: 0.4704016913319239, 1736: 0.5014492753623189, 1993: 0.4477335800185014, 412: 0.5014492753623189, 1012: 0.5073170731707317, 1860: 0.5280487804878049, 2040: 0.6666666666666666, 712: 0.4841750841750842, 1241: 0.47294117647058825, 1244: 0.4690101757631822, 81: 0.4965986394557823, 141: 0.4781144781144781, 145: 0.5676532769556025, 1979: 0.5049833887043189, 1752: 0.46879535558780844, 767: 0.483921568627451, 772: 0.5714285714285714, 1264: 0.4768292682926829, 1578: 0.45701357466063347, 11: 0.5204991087344029, 250: 0.5033738191632928, 1301: 0.8537549407114624, 633: 0.4698581560283688, 779: 0.5093877551020408, 782: 0.5420289855072464, 1024: 0.4744744744744745, 262: 0.5274822695035462, 113: 0.5151020408163265, 357: 0.46304675716440424, 721: 0.4622926093514329, 376: 0.4370567375886525, 906: 0.4422262552934059, 317: 0.5833333333333334, 52: 0.5603543743078627, 167: 0.7509881422924901, 629: 0.42165759225650334, 1707: 0.45614035087719296, 557: 0.6541889483065954, 279: 0.6574712643678161, 1989: 0.5965909090909091, 1995: 0.4104609929078014, 1268: 0.5290148448043185, 896: 0.4513742071881607, 364: 0.4601063829787234, 377: 0.5187165775401069, 2001: 0.5653846153846154, 1761: 0.5193798449612403, 1912: 0.5540780141843972, 1933: 0.5061224489795918, 336: 0.6174242424242424, 387: 0.5210084033613446, 1335: 0.5856236786469344, 1414: 0.7662337662337663, 533: 0.5473484848484849, 1939: 0.5035294117647059, 444: 0.6709677419354839, 1299: 0.8405797101449275, 1610: 0.4796099290780142, 1233: 0.4450354609929078, 1436: 0.4111111111111111, 1780: 0.49551020408163265, 60: 0.45019607843137255, 111: 0.5142857142857142, 951: 0.5535353535353535, 969: 0.6795698924731183, 1077: 0.6636636636636637, 240: 0.44720965309200605, 1148: 0.4076655052264808, 578: 0.4809725158562368, 579: 0.4894795127353267, 2021: 0.7138461538461538, 799: 0.7056451612903226, 70: 0.5454545454545454, 1657: 0.6873949579831933, 1740: 0.6926406926406926, 1775: 0.6205533596837944, 1132: 0.49113475177304966, 127: 0.5768115942028985, 461: 0.45852187028657615, 933: 0.44304682040531096, 297: 0.4326530612244898, 1667: 0.5031446540880503, 1323: 0.48079658605974396, 2004: 0.5887949260042283, 2006: 0.5658914728682171, 645: 0.4564459930313589, 646: 0.6491935483870968, 1554: 0.524966261808367, 1724: 0.6108374384236454, 207: 0.48048780487804876, 420: 0.4188235294117647, 1103: 0.7934782608695652, 1154: 0.4190531852717709, 1999: 0.6423751686909581, 1784: 0.5354239256678281, 1858: 0.46956521739130436, 1441: 0.5319396051103368, 700: 0.4429563492063492, 1560: 0.5507936507936508, 425: 0.5915915915915916, 184: 0.47242380261248185, 1041: 0.6991596638655462, 274: 0.578397212543554, 353: 0.5161616161616162, 1570: 0.4162812210915819, 1842: 0.6092307692307692, 1001: 0.5623188405797102, 949: 0.5025510204081632, 1859: 0.45387755102040817, 1407: 0.5128205128205128, 1899: 0.49714285714285716, 1869: 0.4956862745098039, 1431: 0.5689655172413793, 1689: 0.6634920634920635, 304: 0.48315602836879434, 708: 0.4511784511784512, 16: 0.7662337662337663, 380: 0.5757575757575758, 1405: 0.6367816091954023, 1198: 0.42542372881355933, 1868: 0.4930612244897959, 1688: 0.6456456456456456, 688: 0.5531914893617021, 1057: 0.45771670190274844, 1862: 0.4973404255319149, 2033: 0.5490196078431373, 775: 0.5, 2044: 0.8166666666666667, 83: 0.4878048780487805, 256: 0.5697674418604651, 252: 0.5428571428571428, 1931: 0.5434397163120568, 144: 0.4549019607843137, 1089: 0.5736434108527132, 1926: 0.5380549682875264, 1792: 0.5234708392603129, 2013: 0.4831372549019608, 103: 0.48911465892597966, 1010: 0.5262745098039215, 1810: 0.5721997300944669, 1300: 0.9004329004329005, 1330: 0.5789473684210527, 1250: 0.5105708245243129, 1705: 0.43734335839599, 1310: 0.5203900709219859, 1349: 0.4444444444444444, 329: 0.43089430894308944, 855: 0.4259796806966618, 1648: 0.5393133997785161, 1598: 0.5294117647058824, 639: 0.4645760743321719, 119: 0.5105882352941177, 883: 0.4821256038647343, 831: 0.6666666666666666, 838: 0.5075493612078978, 982: 0.4906122448979592, 200: 0.5846774193548387, 850: 0.7794117647058824, 848: 0.7473684210526316, 7: 0.6307692307692307, 484: 0.4070305272895467, 1770: 0.683076923076923, 345: 0.6602150537634408, 417: 0.47439613526570046, 1789: 0.5305832147937412, 411: 0.7210526315789474, 1513: 0.5187074829931972, 1779: 0.5454545454545454, 182: 0.46078431372549017, 1861: 0.4744897959183674, 406: 0.5795454545454546, 595: 0.4645390070921986, 880: 0.4556862745098039, 485: 0.40193236714975844, 1050: 0.7063492063492064, 180: 0.4238310708898944, 638: 0.46261355695317957, 1219: 0.4873469387755102, 40: 0.4650793650793651, 1836: 0.5814393939393939, 1173: 0.42775510204081635, 1303: 0.6458036984352774, 768: 0.43636363636363634, 1621: 0.5700757575757576, 1846: 0.5900178253119429, 1104: 0.6059743954480796, 588: 0.5370985603543743, 798: 0.8095238095238095, 808: 0.7464387464387464, 1615: 0.4789915966386555, 1943: 0.48103607770582796, 1370: 0.5070921985815603, 1744: 0.46003016591251883, 2015: 0.5121212121212121, 660: 0.4535353535353535, 316: 0.5592469545957918, 1174: 0.4556862745098039, 1189: 0.43058823529411766, 654: 0.5349206349206349, 1682: 0.7494252873563219, 937: 0.4299645390070922, 1559: 0.5806451612903226, 373: 0.49743589743589745, 1809: 0.4787234042553192, 709: 0.49176470588235294, 1184: 0.3838896952104499, 1569: 0.45217391304347826, 1739: 0.6048387096774194, 132: 0.595137420718816, 142: 0.5478723404255319, 1406: 0.514799154334038, 1864: 0.46723044397463004, 1347: 0.45454545454545453, 545: 0.7118226600985221, 846: 0.561344537815126, 1806: 0.5465465465465466, 209: 0.5591397849462365, 1067: 0.7301587301587301, 548: 0.5841463414634146, 1091: 0.5212121212121212, 1544: 0.6206896551724138, 887: 0.45517241379310347, 494: 0.4587737843551797, 507: 0.6274509803921569, 1365: 0.5903271692745377, 1416: 0.8095238095238095, 1114: 0.5084566596194503, 1124: 0.6461538461538462, 1435: 0.6379310344827587, 1134: 0.4379251700680272, 1941: 0.48244897959183675, 615: 0.42781597038603913, 959: 0.4238310708898944, 309: 0.6039488966318235, 892: 0.5243128964059197, 952: 0.5988620199146515, 954: 0.7169230769230769, 867: 0.5038759689922481, 970: 0.6253968253968254, 919: 0.4964705882352941, 1432: 0.6041666666666666, 261: 0.4816326530612245, 451: 0.5, 621: 0.46897163120567376, 1675: 0.5449275362318841, 1699: 0.5833333333333334, 102: 0.5777777777777777, 1215: 0.43186582809224316, 1714: 0.6566666666666666, 441: 0.8842105263157894, 1853: 0.48985507246376814, 339: 0.7083333333333334, 1536: 0.8063241106719368, 647: 0.5492577597840755, 1997: 0.5797979797979798, 1230: 0.44511784511784513, 159: 0.6158730158730159, 1647: 0.4260204081632653, 1721: 0.5586527293844367, 1325: 0.5062388591800356, 597: 0.43521594684385384, 1545: 0.6301075268817204, 305: 0.5495798319327732, 338: 0.626984126984127, 1936: 0.44518272425249167, 508: 0.512012012012012, 815: 0.5420420420420421, 817: 0.5445378151260504, 847: 0.7046153846153846, 1228: 0.4823529411764706, 1712: 0.6695156695156695, 1562: 0.5217948717948718, 870: 0.4830917874396135, 874: 0.40816326530612246, 1730: 0.6081081081081081, 457: 0.4539969834087481, 355: 0.49121184088806663, 524: 0.6206896551724138, 868: 0.525609756097561, 1304: 0.5737373737373738, 1331: 0.6353276353276354, 468: 0.5359848484848485, 1269: 0.4431082331174838, 1076: 0.6396761133603239, 1100: 0.7036290322580645, 408: 0.6235294117647059, 558: 0.7862318840579711, 1110: 0.5206349206349207, 1521: 0.4376470588235294, 1563: 0.5668449197860963, 1568: 0.47038327526132406, 879: 0.4305194805194805, 1046: 0.6713709677419355, 72: 0.6068660022148394, 9: 0.5423280423280423, 428: 0.6923076923076923, 1058: 0.44820295983086683, 109: 0.6493506493506493, 2035: 0.6502463054187192, 241: 0.4070707070707071, 248: 0.5787878787878787, 1172: 0.48308668076109934, 777: 0.5058055152394775, 1583: 0.4203921568627451, 1994: 0.4727061556329849, 1113: 0.5400696864111498, 17: 0.7608695652173914, 992: 0.4869375907111756, 596: 0.48615725359911405, 1917: 0.46219512195121953, 383: 0.6031746031746031, 1003: 0.534850640113798, 264: 0.43097643097643096, 651: 0.6666666666666666, 1753: 0.43546365914786966, 1662: 0.5951219512195122, 1681: 0.7966666666666666, 2041: 0.6571428571428571, 1060: 0.4358974358974359, 663: 0.5256410256410257, 1918: 0.4950213371266003, 1618: 0.6083743842364532, 1708: 0.4517345399698341, 624: 0.41256038647342996, 916: 0.4441489361702128, 1240: 0.4864864864864865, 1358: 0.5913978494623656, 1818: 0.6491935483870968, 718: 0.45050125313283207, 1014: 0.4753623188405797, 310: 0.6048780487804878, 1901: 0.3929292929292929, 1884: 0.611336032388664, 2036: 0.6350806451612904, 1246: 0.4605171208944794, 1487: 0.44784313725490194, 1873: 0.5337763012181617, 1633: 0.5846372688477952, 1636: 0.6699507389162561, 845: 0.5121951219512195, 196: 0.48751156336725254, 2010: 0.4523470839260313, 1676: 0.6276276276276276, 218: 0.6369230769230769, 95: 0.5824524312896406, 1415: 0.9358974358974359, 291: 0.4822190611664296, 64: 0.5525252525252525, 1140: 0.44242424242424244, 1159: 0.4541176470588235, 258: 0.5890243902439024, 281: 0.5613107822410148, 1478: 0.49595959595959593, 1482: 0.44858156028368795, 961: 0.7413793103448276, 1668: 0.4781297134238311, 122: 0.6634920634920635, 1070: 0.635846372688478, 1098: 0.6486486486486487, 630: 0.4202185792349727, 365: 0.5512820512820513, 528: 0.6481481481481481, 114: 0.48627450980392156, 128: 0.6358974358974359, 1498: 0.4323467230443975, 759: 0.543940795559667, 1981: 0.4346153846153846, 517: 0.45876887340301975, 292: 0.4991596638655462, 2023: 0.6798029556650246, 812: 0.7133333333333334, 295: 0.506938775510204, 723: 0.5314009661835749, 1052: 0.6577540106951871, 1445: 0.5913978494623656, 1878: 0.5410628019323671, 534: 0.582010582010582, 1391: 0.40863787375415284, 15: 0.6, 1018: 0.4743107769423559, 1042: 0.7866666666666666, 1940: 0.4965986394557823, 1938: 0.45050125313283207, 350: 0.6491935483870968, 1741: 0.7095238095238096, 389: 0.6679841897233202, 467: 0.47463002114164904, 1207: 0.5333333333333333, 477: 0.435016835016835, 939: 0.46060606060606063, 1085: 0.6992753623188406, 1109: 0.5419630156472262, 2018: 0.554006968641115, 1277: 0.7532467532467533, 986: 0.48403361344537815, 2034: 0.5870967741935483, 1808: 0.558974358974359, 1576: 0.4489795918367347, 1213: 0.5300647548566142, 1644: 0.44920174165457183, 488: 0.4856614246068455, 1227: 0.49411764705882355, 786: 0.4318181818181818, 1122: 0.5766129032258065, 1982: 0.406827880512091, 973: 0.48549019607843136, 1694: 0.5170731707317073, 2037: 0.7193675889328063, 1131: 0.47074468085106386, 335: 0.6554621848739496, 352: 0.5890151515151515, 1520: 0.4170731707317073, 849: 0.8083333333333333, 340: 0.7863247863247863, 1537: 0.7159090909090909, 1588: 0.4782051282051282, 168: 0.7195767195767195, 1065: 0.6733870967741935, 523: 0.5303643724696356, 233: 0.44654088050314467, 583: 0.40420819490586934, 922: 0.46820405310971347, 640: 0.5158730158730159, 784: 0.4713804713804714, 809: 0.8263157894736842, 173: 0.545045045045045, 395: 0.5248933143669986, 1356: 0.5470653377630121, 1965: 0.5428571428571428, 1158: 0.5140096618357488, 1374: 0.4685374149659864, 1271: 0.47780126849894294, 1497: 0.5487179487179488, 656: 0.5849462365591398, 1283: 0.49099099099099097, 306: 0.44563279857397503, 1345: 0.5062056737588653, 147: 0.6831831831831832, 1055: 0.5461538461538461, 581: 0.40627450980392155, 1243: 0.46431372549019606, 1457: 0.5038759689922481, 1401: 0.8947368421052632, 24: 0.43439716312056736, 1909: 0.5463709677419355, 371: 0.695906432748538, 220: 0.6666666666666666, 666: 0.40863787375415284, 57: 0.46616541353383456, 1108: 0.48404255319148937, 414: 0.5169133192389006, 1804: 0.6137931034482759, 1226: 0.46879535558780844, 955: 0.49365750528541225, 1870: 0.5044897959183674, 1377: 0.4686868686868687, 133: 0.5416666666666666, 1353: 0.48403483309143686, 960: 0.6246246246246246, 2007: 0.5966386554621849, 644: 0.4946236559139785, 1797: 0.5435435435435435, 1653: 0.7364532019704434, 1691: 0.6171171171171171, 289: 0.5060483870967742, 543: 0.6487394957983194, 1403: 0.7118279569892473, 1210: 0.5505226480836237, 1529: 0.5379310344827586, 550: 0.7723076923076924, 1793: 0.6305418719211823, 893: 0.4579710144927536, 1105: 0.5222222222222223, 1813: 0.632258064516129, 1783: 0.6455026455026455, 1834: 0.5033816425120773, 802: 0.6466666666666666, 0: 0.6493506493506493, 502: 0.4931972789115646, 749: 0.5087082728592163, 469: 0.5365418894830659, 2030: 0.51, 1111: 0.62, 1969: 0.5195402298850574, 1814: 0.6007130124777184, 347: 0.5544354838709677, 1341: 0.4365750528541226, 1976: 0.5301418439716312, 1827: 0.5200845665961945, 1637: 0.6772486772486772, 1337: 0.5238095238095238, 418: 0.4575757575757576, 941: 0.44830917874396137, 1466: 0.8627450980392157, 1461: 0.442512077294686, 187: 0.4530141843971631, 1815: 0.632183908045977, 308: 0.7660818713450293, 1203: 0.48717948717948717, 136: 0.477891156462585, 1206: 0.6580645161290323, 152: 0.7253787878787878, 8: 0.4751066856330014, 1958: 0.4956862745098039, 732: 0.442512077294686, 1590: 0.4619607843137255, 213: 0.5714285714285714, 1980: 0.46096096096096095, 1369: 0.7107692307692308, 1945: 0.5191836734693878, 1320: 0.5272895467160037, 243: 0.41352657004830917, 1812: 0.6597701149425287, 1816: 0.7761904761904762, 1985: 0.5391156462585034, 822: 0.5052264808362369, 343: 0.84, 753: 0.44387755102040816, 872: 0.44234800838574423, 1526: 0.5891472868217055, 1069: 0.638095238095238, 458: 0.5008503401360545, 1047: 0.6084033613445378, 1555: 0.5263157894736842, 1212: 0.5373737373737374, 416: 0.5357624831309041, 873: 0.47058823529411764, 1762: 0.507399577167019, 1911: 0.5669515669515669, 37: 0.6099865047233468, 1921: 0.5555555555555556, 818: 0.5195195195195195, 1680: 0.7215909090909091, 813: 0.64, 1531: 0.638095238095238, 601: 0.48639455782312924, 1456: 0.47641073080481033, 1572: 0.4065040650406504, 1465: 0.7101449275362319, 1854: 0.5060606060606061, 156: 0.8052631578947368, 100: 0.6724137931034483, 1844: 0.5889328063241107, 1061: 0.6795698924731183, 1922: 0.6617647058823529, 1897: 0.5159183673469387, 1532: 0.8181818181818182, 1525: 0.5381642512077295, 1717: 0.66, 617: 0.4744933612858141, 1419: 0.5195195195195195, 358: 0.46431372549019606, 198: 0.4706533776301218, 1119: 0.4174603174603175, 1821: 0.558974358974359, 1839: 0.6060606060606061, 1262: 0.45217391304347826, 1852: 0.5439024390243903, 974: 0.4996078431372549, 1030: 0.523936170212766, 1888: 0.6559139784946236, 1389: 0.44629014396456257, 572: 0.46153846153846156, 1137: 0.4595918367346939, 694: 0.4375578168362627, 1462: 0.5270935960591133, 1955: 0.5526024363233666, 71: 0.5132275132275133, 1222: 0.4557823129251701, 405: 0.5353658536585366, 1795: 0.6190476190476191, 2027: 0.5376955903271693, 1920: 0.5968379446640316, 791: 0.6032388663967612, 124: 0.5290322580645161, 149: 0.6818181818181818, 827: 0.6043010752688172, 278: 0.7195402298850575, 1711: 0.6931216931216931, 1232: 0.5144557823129252, 541: 0.5216326530612245, 222: 0.7818181818181819, 1541: 0.66890756302521, 1249: 0.5071982281284607, 740: 0.5257142857142857, 530: 0.6166666666666667, 866: 0.5097560975609756, 1294: 0.6231231231231231, 68: 0.50472334682861, 1788: 0.49682875264270615, 2020: 0.6638176638176638, 1281: 0.5025641025641026, 1332: 0.8021978021978022, 300: 0.5383903792784459, 819: 0.4606845513413506, 1348: 0.4330011074197121, 1453: 0.6205533596837944, 1282: 0.5480480480480481, 1311: 0.5050980392156863, 1929: 0.4274099883855981, 66: 0.5939024390243902, 370: 0.6666666666666666, 1629: 0.5897435897435898, 107: 0.6413793103448275, 158: 0.6429587482219061, 565: 0.5110336817653891, 569: 0.9047619047619048, 1308: 0.8954248366013072, 913: 0.445578231292517, 1422: 0.44747474747474747, 1966: 0.5467980295566502, 862: 0.47874149659863946, 170: 0.6733870967741935, 682: 0.4956140350877193, 699: 0.43676395289298514, 1005: 0.7272727272727273, 221: 0.725, 1157: 0.45224489795918366, 586: 0.4767676767676768, 1298: 0.5951219512195122, 1511: 0.4419306184012066, 888: 0.580952380952381, 120: 0.5725359911406424, 1040: 0.7486772486772487, 538: 0.558974358974359, 150: 0.6876876876876877, 956: 0.46598639455782315, 54: 0.78, 386: 0.5492424242424242, 393: 0.5181159420289855, 1471: 0.8380952380952381, 249: 0.6448717948717949, 280: 0.7445887445887446, 75: 0.5656565656565656, 5: 0.67, 1097: 0.6205533596837944, 1379: 0.5012820512820513, 1285: 0.5797101449275363, 1307: 0.7316017316017316, 2011: 0.5040322580645161, 1642: 0.5516840882694541, 246: 0.5353535353535354, 1221: 0.4440333024976873, 1627: 0.6666666666666666, 806: 0.6672268907563025, 612: 0.4474025974025974, 1684: 0.8263157894736842, 1101: 0.7433333333333333, 1972: 0.49924585218702866, 662: 0.4750337381916329, 313: 0.7192118226600985, 652: 0.6904761904761905, 391: 0.5189393939393939, 1469: 0.7973856209150327, 899: 0.41585365853658535, 1074: 0.7023172905525846, 251: 0.5862068965517241, 162: 0.5227021040974529, 1523: 0.4263565891472868, 1121: 0.526829268292683, 1898: 0.5067873303167421, 1351: 0.44390243902439025, 717: 0.5082956259426847, 1334: 0.8974358974358975, 859: 0.6739130434782609, 2003: 0.6369230769230769, 1426: 0.6137931034482759, 62: 0.37907268170426067, 1289: 0.5902439024390244, 1803: 0.5177809388335705, 1336: 0.5217391304347826, 1470: 0.6838235294117647, 1528: 0.48792270531400966, 1791: 0.5885057471264368, 203: 0.45555555555555555, 432: 0.6645161290322581, 1589: 0.4336349924585219, 118: 0.46088193456614507, 685: 0.4685714285714286, 396: 0.5151515151515151, 1448: 0.5391180654338549, 1769: 0.615530303030303, 204: 0.39806763285024155, 966: 0.5383064516129032, 379: 0.5507936507936508, 1408: 0.45365853658536587, 1546: 0.6307692307692307, 881: 0.49696969696969695, 499: 0.5044326241134752, 452: 0.5063492063492063, 907: 0.45584415584415583, 2: 0.6738461538461539, 1660: 0.7023172905525846, 1136: 0.47058823529411764, 1291: 0.5171717171717172, 582: 0.38454106280193234, 1409: 0.6123076923076923, 977: 0.4907539118065434, 1774: 0.6233333333333333, 1263: 0.45217391304347826, 1890: 0.6752136752136753, 1259: 0.4642857142857143, 820: 0.5040650406504065, 1641: 0.5044326241134752, 1679: 0.6987522281639929, 1593: 0.47246376811594204, 1742: 0.7794117647058824, 1413: 0.6766666666666666, 1473: 0.6666666666666666, 2002: 0.6290322580645161, 116: 0.4709851551956815, 1078: 0.78, 229: 0.644927536231884, 556: 0.5519568151147098, 1452: 0.5952380952380952, 1771: 0.5634920634920635, 1840: 0.5697478991596638, 836: 0.5630630630630631, 385: 0.6926406926406926, 1179: 0.4487012987012987, 884: 0.4878048780487805, 839: 0.5126984126984127, 1651: 0.592469545957918, 1542: 0.6325757575757576, 185: 0.4626262626262626, 547: 0.6412698412698413, 1624: 0.5541871921182266, 88: 0.5283687943262412, 18: 0.7028985507246377, 1551: 0.7333333333333333, 1017: 0.6031746031746031, 559: 0.7666666666666667, 537: 0.6160919540229886, 1420: 0.553968253968254, 1734: 0.604551920341394, 1275: 0.5704099821746881, 76: 0.6837121212121212, 1760: 0.44847605224963716, 1690: 0.6494623655913978, 2039: 0.6789473684210526, 658: 0.47463002114164904, 1923: 0.5165912518853696, 1650: 0.6275303643724697, 2038: 0.7017543859649122, 608: 0.47215686274509805, 429: 0.7384615384615385, 6: 0.6640316205533597, 1359: 0.5954415954415955, 342: 0.8789473684210526, 1879: 0.5217391304347826, 1399: 0.7806267806267806, 810: 0.5650793650793651, 1686: 0.8916666666666667, 858: 0.5299145299145299, 435: 0.5470085470085471, 211: 0.7421052631578947, 22: 0.5747899159663865, 137: 0.47908232118758437, 322: 0.8333333333333334, 374: 0.5543672014260249, 1043: 0.8023715415019763, 794: 0.5218390804597701, 554: 0.6216216216216216, 1417: 1.0, 1883: 0.63, 1817: 0.8602941176470589, 1333: 1.0, 1360: 0.5497076023391813, 172: 0.5492063492063493, 1051: 0.7315789473684211, 1628: 0.8181818181818182, 228: 0.7578947368421053, 1455: 0.725}\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import torch\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "def compute_graph_features(data):\n",
    "    # Convert PyTorch Geometric Data to NetworkX graph\n",
    "    edge_index = data.edge_index.cpu().numpy()\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(edge_index.T)\n",
    "\n",
    "    # Compute node degrees\n",
    "    degrees = dict(G.degree())\n",
    "\n",
    "    # Compute clustering coefficients\n",
    "    clustering_coeffs = nx.clustering(G)\n",
    "\n",
    "    return {\n",
    "        \"degree\": degrees,\n",
    "        \"clustering_coefficient\": clustering_coeffs\n",
    "    }\n",
    "\n",
    "# Example usage with DataLoader\n",
    "for data in dataset_loader:\n",
    "    features = compute_graph_features(data)\n",
    "    print(f\"Degrees: {features['degree']}\")\n",
    "    print(f\"Clustering Coefficients: {features['clustering_coefficient']}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "754ca098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of graphs: 85\n",
      "DataBatch(x=[2216, 4], edge_index=[2, 42974], edge_attr=[42974, 1], y=[2216], batch=[2216], ptr=[2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-98bd02075ec5>:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0]) if os.path.exists(self.processed_paths[0]) else self.process()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, InMemoryDataset, DataLoader\n",
    "from torch_geometric.utils import from_networkx\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from scipy.spatial import KDTree\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Detect CUDA availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Path to the directory containing PDB files\n",
    "pdb_dir = \"D:\\\\P2Rank_GNN_Dataset\\\\chen11\"\n",
    "\n",
    "# Get a list of all PDB files in the directory\n",
    "pdb_files = glob.glob(os.path.join(pdb_dir, \"*.pdb\"))\n",
    "\n",
    "def validate_and_fix_mol(mol):\n",
    "    if mol is None:\n",
    "        return None\n",
    "    try:\n",
    "        for atom in mol.GetAtoms():\n",
    "            if atom.GetExplicitValence() > Chem.GetPeriodicTable().GetDefaultValence(atom.GetAtomicNum()):\n",
    "                return None  # Ignore molecules with incorrect valence\n",
    "        Chem.SanitizeMol(mol)\n",
    "        return mol\n",
    "    except Exception as e:\n",
    "        print(f\"Error sanitizing molecule: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_sas_points(pdb_file):\n",
    "    try:\n",
    "        mol = Chem.MolFromPDBFile(pdb_file, removeHs=False, sanitize=False)\n",
    "        mol = validate_and_fix_mol(mol)\n",
    "        if mol is None:\n",
    "            return None\n",
    "\n",
    "        conf = mol.GetConformer()\n",
    "        sas_points = np.array([[conf.GetAtomPosition(atom.GetIdx()).x,\n",
    "                                conf.GetAtomPosition(atom.GetIdx()).y,\n",
    "                                conf.GetAtomPosition(atom.GetIdx()).z] for atom in mol.GetAtoms()])\n",
    "        \n",
    "        return sas_points if sas_points.size > 0 else None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing PDB file {pdb_file}: {e}\")\n",
    "        return None\n",
    "\n",
    "def construct_edges(sas_points, distance_threshold=6.0):\n",
    "    if len(sas_points) == 0:\n",
    "        return np.empty((0, 2), dtype=np.int64)\n",
    "\n",
    "    tree = KDTree(sas_points)\n",
    "    pairs = tree.query_pairs(distance_threshold)\n",
    "    edges = np.array(list(pairs))\n",
    "\n",
    "    return edges if edges.size > 0 else np.empty((0, 2), dtype=np.int64)\n",
    "\n",
    "def compute_local_graph_features(edges, num_nodes):\n",
    "    degree = np.zeros(num_nodes, dtype=np.float32)\n",
    "    for i, j in edges:\n",
    "        degree[i] += 1\n",
    "        degree[j] += 1\n",
    "    return torch.tensor(degree).view(-1, 1)  # Degree as node feature\n",
    "\n",
    "def process_pdb_file(pdb_file):\n",
    "    sas_points = extract_sas_points(pdb_file)\n",
    "    if sas_points is None:\n",
    "        return None\n",
    "\n",
    "    edges = construct_edges(sas_points)\n",
    "    edge_index = torch.tensor(edges.T, dtype=torch.long) if edges.size > 0 else torch.empty((2, 0), dtype=torch.long)\n",
    "    edge_features = torch.tensor([[np.linalg.norm(sas_points[i] - sas_points[j])] for i, j in edges], dtype=torch.float) if edges.size > 0 else torch.empty((0, 1), dtype=torch.float)\n",
    "\n",
    "    node_features = torch.tensor(sas_points, dtype=torch.float)\n",
    "    local_graph_features = compute_local_graph_features(edges, len(sas_points))\n",
    "    combined_node_features = torch.cat([node_features, local_graph_features], dim=1)\n",
    "\n",
    "    labels = torch.full((len(sas_points),), 0.5, dtype=torch.float)  \n",
    "\n",
    "    data = Data(\n",
    "        x=combined_node_features.to(device),\n",
    "        edge_index=edge_index.to(device),\n",
    "        edge_attr=edge_features.to(device),\n",
    "        y=labels.to(device)\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "class ProteinGraphDataset(InMemoryDataset):\n",
    "    def __init__(self, root, pdb_files, transform=None, pre_transform=None):\n",
    "        self.pdb_files = pdb_files\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0]) if os.path.exists(self.processed_paths[0]) else self.process()\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [\"protein_graphs.pt\"]\n",
    "\n",
    "    def process(self):\n",
    "        data_list = Parallel(n_jobs=8)(delayed(process_pdb_file)(pdb) for pdb in self.pdb_files)\n",
    "        data_list = [d for d in data_list if d is not None]\n",
    "        print(f\"Processed {len(data_list)} graphs out of {len(self.pdb_files)} PDB files.\")\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "        return data, slices\n",
    "\n",
    "    def get(self, idx):\n",
    "        return super().get(idx)\n",
    "\n",
    "protein_graph_dataset = ProteinGraphDataset(root='protein_data', pdb_files=pdb_files)\n",
    "dataset_loader = DataLoader(protein_graph_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "print(f\"Total number of graphs: {len(protein_graph_dataset)}\")\n",
    "\n",
    "for data in dataset_loader:\n",
    "    print(data)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d171a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 2898.3482\n",
      "Epoch 2/50, Loss: 2305.1294\n",
      "Epoch 3/50, Loss: 1851.2688\n",
      "Epoch 4/50, Loss: 1500.8197\n",
      "Epoch 5/50, Loss: 1295.1101\n",
      "Epoch 6/50, Loss: 997.6453\n",
      "Epoch 7/50, Loss: 838.5537\n",
      "Epoch 8/50, Loss: 750.2469\n",
      "Epoch 9/50, Loss: 626.2530\n",
      "Epoch 10/50, Loss: 562.7170\n",
      "Epoch 11/50, Loss: 502.6624\n",
      "Epoch 12/50, Loss: 497.6691\n",
      "Epoch 13/50, Loss: 400.3780\n",
      "Epoch 14/50, Loss: 374.6241\n",
      "Epoch 15/50, Loss: 357.9088\n",
      "Epoch 16/50, Loss: 331.5323\n",
      "Epoch 17/50, Loss: 315.0074\n",
      "Epoch 18/50, Loss: 326.9326\n",
      "Epoch 19/50, Loss: 292.6086\n",
      "Epoch 20/50, Loss: 274.7918\n",
      "Epoch 21/50, Loss: 269.6394\n",
      "Epoch 22/50, Loss: 259.1256\n",
      "Epoch 23/50, Loss: 245.0397\n",
      "Epoch 24/50, Loss: 231.5599\n",
      "Epoch 25/50, Loss: 236.5069\n",
      "Epoch 26/50, Loss: 231.4348\n",
      "Epoch 27/50, Loss: 235.1608\n",
      "Epoch 28/50, Loss: 214.2791\n",
      "Epoch 29/50, Loss: 218.0996\n",
      "Epoch 30/50, Loss: 210.0375\n",
      "Epoch 31/50, Loss: 208.6964\n",
      "Epoch 32/50, Loss: 199.3753\n",
      "Epoch 33/50, Loss: 202.2251\n",
      "Epoch 34/50, Loss: 208.1266\n",
      "Epoch 35/50, Loss: 196.6840\n",
      "Epoch 36/50, Loss: 187.9598\n",
      "Epoch 37/50, Loss: 194.0219\n",
      "Epoch 38/50, Loss: 188.9153\n",
      "Epoch 39/50, Loss: 185.0236\n",
      "Epoch 40/50, Loss: 190.3038\n",
      "Epoch 41/50, Loss: 181.1628\n",
      "Epoch 42/50, Loss: 190.7390\n",
      "Epoch 43/50, Loss: 178.3149\n",
      "Epoch 44/50, Loss: 179.4575\n",
      "Epoch 45/50, Loss: 182.7476\n",
      "Epoch 46/50, Loss: 180.0994\n",
      "Epoch 47/50, Loss: 180.9909\n",
      "Epoch 48/50, Loss: 176.2728\n",
      "Epoch 49/50, Loss: 181.3265\n",
      "Epoch 50/50, Loss: 180.8878\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the GCN Encoder\n",
    "class GCNEncoder(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_dim, hidden_dim)\n",
    "        self.conv_mu = GCNConv(hidden_dim, latent_dim)  # Mean of latent space\n",
    "        self.conv_logvar = GCNConv(hidden_dim, latent_dim)  # Log variance\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        mu = self.conv_mu(x, edge_index)\n",
    "        logvar = self.conv_logvar(x, edge_index)\n",
    "        return mu, logvar\n",
    "\n",
    "# Define the Variational Autoencoder (VAE)\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = GCNEncoder(in_dim, hidden_dim, latent_dim)\n",
    "        self.decoder = GCNConv(latent_dim, in_dim)  # Reconstruct original input\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(logvar / 2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        mu, logvar = self.encoder(x, edge_index)  # Encode input\n",
    "        logvar = torch.clamp(logvar, min=-10, max=10)  # Stabilize variance\n",
    "        z = self.reparameterize(mu, logvar)  # Sample latent vector\n",
    "        recon_x = self.decoder(z, edge_index)  # Reconstruct input\n",
    "        return recon_x, mu, logvar\n",
    "\n",
    "# VAE Loss Function\n",
    "def vae_loss(recon_x, x, mu, logvar):\n",
    "    recon_loss = F.mse_loss(recon_x, x, reduction='mean')  # Reconstruction Loss\n",
    "    kl_div = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())  # KL Divergence\n",
    "    return recon_loss + kl_div\n",
    "\n",
    "# Training Function\n",
    "def train_vae(model, dataloader, optimizer, device, epochs=50):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for data in dataloader:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            recon_x, mu, logvar = model(data.x, data.edge_index)\n",
    "            loss = vae_loss(recon_x, data.x, mu, logvar)\n",
    "            \n",
    "            if torch.isnan(loss):  # Check for NaN loss\n",
    "                print(f\"NaN encountered at epoch {epoch+1}, skipping update...\")\n",
    "                continue  # Skip update to prevent corrupting weights\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Ensure dataset is valid (avoid NaNs)\n",
    "def check_dataset(dataset):\n",
    "    for i, data in enumerate(dataset):\n",
    "        if torch.isnan(data.x).any():\n",
    "            print(f\"NaN detected in node features of graph {i}\")\n",
    "        if torch.isnan(data.edge_index).any():\n",
    "            print(f\"NaN detected in edge index of graph {i}\")\n",
    "\n",
    "# Initialize Model and Training Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Check dataset before training\n",
    "check_dataset(protein_graph_dataset)\n",
    "\n",
    "model = VAE(in_dim=protein_graph_dataset[0].x.shape[1], hidden_dim=64, latent_dim=32).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)  # Reduced LR for stability\n",
    "\n",
    "# Use the processed protein dataset\n",
    "dataloader = DataLoader(protein_graph_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Train the Model\n",
    "train_vae(model, dataloader, optimizer, device, epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6dc292f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.loader import DataLoader  # Use PyG DataLoader\n",
    "\n",
    "# Use the processed protein dataset\n",
    "dataloader = DataLoader(protein_graph_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "def get_link_labels(edge_index, num_nodes):\n",
    "    \"\"\"\n",
    "    Generate positive and negative edges for link prediction.\n",
    "    \"\"\"\n",
    "    # Positive edges (existing edges)\n",
    "    pos_edge_index = edge_index\n",
    "\n",
    "    # Negative edges (randomly sampled non-existent edges)\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=edge_index, num_nodes=num_nodes, num_neg_samples=edge_index.size(1)\n",
    "    )\n",
    "\n",
    "    # Labels: 1 for positive edges, 0 for negative edges\n",
    "    edge_labels = torch.cat([\n",
    "        torch.ones(pos_edge_index.size(1)),  # Positive labels\n",
    "        torch.zeros(neg_edge_index.size(1))  # Negative labels\n",
    "    ]).to(torch.float)\n",
    "\n",
    "    # Combine positive and negative edges\n",
    "    combined_edges = torch.cat([pos_edge_index, neg_edge_index], dim=1)\n",
    "\n",
    "    return combined_edges, edge_labels\n",
    "\n",
    "# Process the protein dataset batch-wise\n",
    "for batch in dataloader:\n",
    "    batch = batch.to('cuda' if torch.cuda.is_available() else 'cpu')  # Move to GPU if available\n",
    "    combined_edges, edge_labels = get_link_labels(batch.edge_index, batch.num_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afcdce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "class LinkPredictor(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_dim, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, 1)  # Concatenate node pairs\n",
    "\n",
    "    def forward(self, x, edge_index, combined_edges):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "\n",
    "        # Extract node embeddings from batched graph\n",
    "        src = x[combined_edges[0]]  # Source nodes\n",
    "        dst = x[combined_edges[1]]  # Destination nodes\n",
    "        edge_features = torch.cat([src, dst], dim=1)  # Concatenate features\n",
    "\n",
    "        return torch.sigmoid(self.fc(edge_features)).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c3a4c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 9.5393, Accuracy: 0.4780\n",
      "Epoch 10, Loss: 4.1608, Accuracy: 0.4957\n",
      "Epoch 20, Loss: 4.1538, Accuracy: 0.5057\n",
      "Epoch 30, Loss: 4.1465, Accuracy: 0.5250\n",
      "Epoch 40, Loss: 4.1307, Accuracy: 0.5537\n",
      "Epoch 50, Loss: 4.1049, Accuracy: 0.5630\n",
      "Epoch 60, Loss: 4.0816, Accuracy: 0.5727\n",
      "Epoch 70, Loss: 4.0584, Accuracy: 0.5741\n",
      "Epoch 80, Loss: 4.0557, Accuracy: 0.5839\n",
      "Epoch 90, Loss: 4.0481, Accuracy: 0.5788\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Function to get positive & negative edges for training\n",
    "def get_link_labels(edge_index, num_nodes):\n",
    "    device = edge_index.device\n",
    "    num_edges = edge_index.size(1)\n",
    "\n",
    "    # Positive edges (existing edges)\n",
    "    pos_edges = edge_index\n",
    "\n",
    "    # Generate negative edges (random pairs that are not connected)\n",
    "    neg_edges = torch.randint(0, num_nodes, (2, num_edges), device=device)\n",
    "    \n",
    "    # Concatenate positive and negative edges\n",
    "    combined_edges = torch.cat([pos_edges, neg_edges], dim=1)\n",
    "    \n",
    "    # Labels: 1 for positive edges, 0 for negative edges\n",
    "    edge_labels = torch.cat([torch.ones(num_edges), torch.zeros(num_edges)], dim=0).to(device)\n",
    "\n",
    "    return combined_edges, edge_labels\n",
    "\n",
    "# Link Predictor Model\n",
    "class LinkPredictor(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_dim, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, 1)  # Concat source & target embeddings\n",
    "\n",
    "    def forward(self, x, edge_index, combined_edges):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "\n",
    "        # Extract node embeddings\n",
    "        src = x[combined_edges[0]]\n",
    "        dst = x[combined_edges[1]]\n",
    "        edge_features = torch.cat([src, dst], dim=1)\n",
    "\n",
    "        return torch.sigmoid(self.fc(edge_features)).squeeze()\n",
    "\n",
    "# DataLoader for batched training\n",
    "dataloader = DataLoader(protein_graph_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Dynamically infer input feature dimension\n",
    "sample_data = next(iter(dataloader))\n",
    "in_dim = sample_data.x.shape[1]  # Automatically get feature dimension\n",
    "\n",
    "# Initialize model, optimizer, and loss function\n",
    "link_predictor = LinkPredictor(in_dim=in_dim, hidden_dim=32)\n",
    "optimizer = torch.optim.Adam(link_predictor.parameters(), lr=0.01)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "link_predictor = link_predictor.to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    link_predictor.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        combined_edges, edge_labels = get_link_labels(batch.edge_index, batch.num_nodes)\n",
    "        edge_labels = edge_labels.to(device)\n",
    "\n",
    "        pred = link_predictor(batch.x, batch.edge_index, combined_edges)\n",
    "        loss = loss_fn(pred, edge_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        acc = ((pred > 0.5) == edge_labels).float().mean().item()\n",
    "        print(f'Epoch {epoch}, Loss: {total_loss:.4f}, Accuracy: {acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a727a2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# Improved negative sampling strategy\n",
    "def get_link_labels(edge_index, num_nodes):\n",
    "    device = edge_index.device\n",
    "    num_edges = edge_index.size(1)\n",
    "\n",
    "    pos_edges = edge_index\n",
    "\n",
    "    # Hard negative sampling: sample from nodes that are closer in graph structure\n",
    "    neg_edges = torch.randint(0, num_nodes, (2, num_edges), device=device)\n",
    "    \n",
    "    # Avoid sampling existing edges\n",
    "    mask = torch.isin(neg_edges, pos_edges).any(dim=0)\n",
    "    while mask.any():\n",
    "        neg_edges[:, mask] = torch.randint(0, num_nodes, (2, mask.sum()), device=device)\n",
    "        mask = torch.isin(neg_edges, pos_edges).any(dim=0)\n",
    "\n",
    "    # Concatenate positive & negative edges\n",
    "    combined_edges = torch.cat([pos_edges, neg_edges], dim=1)\n",
    "    edge_labels = torch.cat([torch.ones(num_edges), torch.zeros(num_edges)], dim=0).to(device)\n",
    "\n",
    "    return combined_edges, edge_labels\n",
    "\n",
    "# Enhanced Link Predictor Model\n",
    "class LinkPredictor(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_dim, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = SAGEConv(hidden_dim, hidden_dim)  # Added one more layer\n",
    "        self.fc = nn.Linear(hidden_dim * 2, 1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x, edge_index, combined_edges):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Extract node embeddings\n",
    "        src = x[combined_edges[0]]\n",
    "        dst = x[combined_edges[1]]\n",
    "        edge_features = torch.cat([src, dst], dim=1)\n",
    "\n",
    "        return self.fc(edge_features).squeeze()  \n",
    "\n",
    "# DataLoader\n",
    "dataloader = DataLoader(protein_graph_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Get input feature dimension dynamically\n",
    "sample_data = next(iter(dataloader))\n",
    "in_dim = sample_data.x.shape[1]  \n",
    "\n",
    "# Model, Optimizer, and Loss\n",
    "link_predictor = LinkPredictor(in_dim=in_dim, hidden_dim=64)  # Increased hidden size\n",
    "optimizer = torch.optim.AdamW(link_predictor.parameters(), lr=0.005, weight_decay=1e-4)\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.8)  # Learning rate decay\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "link_predictor = link_predictor.to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    link_predictor.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        combined_edges, edge_labels = get_link_labels(batch.edge_index, batch.num_nodes)\n",
    "        edge_labels = edge_labels.to(device)\n",
    "\n",
    "        pred = link_predictor(batch.x, batch.edge_index, combined_edges)\n",
    "        loss = loss_fn(pred, edge_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Compute accuracy\n",
    "    with torch.no_grad():\n",
    "        acc = ((torch.sigmoid(pred) > 0.5) == edge_labels).float().mean().item()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {total_loss:.4f}, Accuracy: {acc:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
